[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to R",
    "section": "",
    "text": "Intro to R: A Hands on Tutorial\nThis book contains the materials for Intro to R: A hands-on tutorial, a multi-class R training hosted by the Urban Institute R Users Group.\nCore lessons include:"
  },
  {
    "objectID": "index.html#instructors-across-all-years",
    "href": "index.html#instructors-across-all-years",
    "title": "Intro to R",
    "section": "Instructors (across all years)",
    "text": "Instructors (across all years)\n\nAaron R. Williams (IBP/TECH)\nAmy Rogin (MET)\nAjjit Narayanan (TECH)\nFay Walker (MET)\nSarah Strochak (HFPC)\nKyle Ueyama (TECH)\nOlivia Fiol (MET)\n\n\nQuestions?\nContact Amy Rogin (arogin@urban.org) or Aaron Williams (awilliams@urban.org)"
  },
  {
    "objectID": "01_lesson.html#review",
    "href": "01_lesson.html#review",
    "title": "1  Data Visualization",
    "section": "1.1 Review",
    "text": "1.1 Review\nWhy Use R instead of Excel?\n\nReproducibility\nScalability\nFlexibility\nIterative\nOpen Source\n\nRemember\n\nEnvironment/scripts/console\nComment your code as you go\nRead your error messages\nWhere possible, type, don’t copy and paste - you will remember better!\nThe assignment operator"
  },
  {
    "objectID": "01_lesson.html#exercise-0-set-up-a-project-and-load-packages",
    "href": "01_lesson.html#exercise-0-set-up-a-project-and-load-packages",
    "title": "1  Data Visualization",
    "section": "1.2 Exercise 0 (Set up a project and load packages)",
    "text": "1.2 Exercise 0 (Set up a project and load packages)\nStep 1: Open RStudio. File &gt; New Project &gt; New Directory &gt; Select the location where you would like to create a new folder that houses your R Project. Call it urbn101\nStep 2: Open an .R script with the button in the top left (sheet with a plus sign icon). Save the script as 01_data-visualization.R.\nStep 3: Type install.packages(\"tidyverse\") and hit enter (submit) to the Console.\nStep 4: Write library(tidyverse) and at the top of 01_data-visualization.R. With the cursor on the line of text, hit Control-Enter (at the same time).\nStep 5: Repeat steps 3 & 4 with install.packages(\"ggplot2\") and library(ggplot2), respectively.\n\ntidyverse - a collection of libraries that use the same syntax/grammar (more on this on Monday)\nggplot2 - for making plots/graphs"
  },
  {
    "objectID": "01_lesson.html#exercise-1-make-a-plot",
    "href": "01_lesson.html#exercise-1-make-a-plot",
    "title": "1  Data Visualization",
    "section": "1.3 Exercise 1 (Make a plot)",
    "text": "1.3 Exercise 1 (Make a plot)\nStep 1: Submit data() to the console. We will use the airquality dataset.\nStep 2: Type the following in your script:\nggplot(data=airquality)+\n  geom_point(mapping=aes(x=Temp, y=Ozone))\n\nData frames are the only appropriate input for library(ggplot2).\n\nStep 3: Add a comment above the ggplot2 code that describes the plot we created.\nStep 4: Add comments below the data visualization code that describes the argument or function that corresponds to each of the first three components of the grammar of graphics.\nData are the values represented in the visualization.\nAesthetic mappings are directions for how data are mapped in a plot in a way that we can perceive. Aesthetic mappings include linking variables to the x-position, y-position, color, fill, shape, transparency, and size.\nGeometric objects are representations of the data, including points, lines, and polygons."
  },
  {
    "objectID": "01_lesson.html#exercise-2-change-some-of-the-plot-settings",
    "href": "01_lesson.html#exercise-2-change-some-of-the-plot-settings",
    "title": "1  Data Visualization",
    "section": "1.4 Exercise 2 (Change some of the plot settings)",
    "text": "1.4 Exercise 2 (Change some of the plot settings)\nStep 1: Duplicate the code from your first chart. Inside aes(), add color = \"red\" (separated by a comma)\nStep 2: Move color = \"red\" from aes() to geom_point(). What changed?\nStep 3: Remove color = \"red\" and add color = Month inside aes().\nStep 4: This is a little cluttered. Add alpha = 0.2 inside geom_point().\nStep 5: Add a plus sign to the end of the geom_point line, type labs(title=\"Air Quality Temperature and Ozone Readings\")\nAesthetic mappings like x and y almost always vary with the data. Aesthetic mappings like color, fill, shape, transparency, and size can vary with the data. But those arguments can also be added as styles that don’t vary with the data. If you include those arguments in aes(), they will show up in the legend (which can be annoying!)."
  },
  {
    "objectID": "01_lesson.html#exercise-3-add-a-regression-lineconfidence-interval",
    "href": "01_lesson.html#exercise-3-add-a-regression-lineconfidence-interval",
    "title": "1  Data Visualization",
    "section": "1.5 Exercise 3 (Add a regression line/confidence interval)",
    "text": "1.5 Exercise 3 (Add a regression line/confidence interval)\nStep 1: Reconfigure the data so that the geompoint parentheses are empty (move mapping=aes(x=Temp, y=Ozone) to the ggplot line. Add + to the labs line and add geom_smooth()"
  },
  {
    "objectID": "01_lesson.html#exercise-4-scale-the-axes",
    "href": "01_lesson.html#exercise-4-scale-the-axes",
    "title": "1  Data Visualization",
    "section": "1.6 Exercise 4 (Scale the axes)",
    "text": "1.6 Exercise 4 (Scale the axes)\nStep 1: Create a new scatter plot using the msleep data set. Use bodywt on the x-axis and sleep_total on the y-axis.\nStep 2: The y-axis doesn’t contain zero. Below geom_point(), add scale_y_continuous(lim = c(0, NA)). Hint: add + after geom_point().\nStep 3: The x-axis is clustered near zero. Add scale_x_log10() above scale_y_continuous(lim = c(0, NA)).\nScales Turn data values, which are quantitative or categorical, into aesthetic values. This includes not only the x-axis and y-axis, but the ranges of sizes, shapes, and colors of aesthetics."
  },
  {
    "objectID": "01_lesson.html#exercise-5-make-it-look-nice",
    "href": "01_lesson.html#exercise-5-make-it-look-nice",
    "title": "1  Data Visualization",
    "section": "1.7 Exercise 5 (Make it look nice!!)",
    "text": "1.7 Exercise 5 (Make it look nice!!)\nStep 1: Add the following code to your script. Submit it!\nggplot(storms)+ \ngeom_bar(mapping=aes(category))\nStep 2: Run install.packages(\"remotes\") and remotes::install_github(\"UrbanInstitute/urbnthemes\") in the console.\nStep 3: In the lines preceding the chart add and run the following code:\nlibrary(urbnthemes)\nset_urbn_defaults(style = \"print\")\nStep 4: Run the code to make the chart.\nStep 5: Add scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) and rerun the code.\nTheme controls the visual style of plot with font types, font sizes, background colors, margins, and positioning."
  },
  {
    "objectID": "01_lesson.html#excercise-6-multiple-little-graphsfaceting",
    "href": "01_lesson.html#excercise-6-multiple-little-graphsfaceting",
    "title": "1  Data Visualization",
    "section": "1.8 Excercise 6 (Multiple little graphs/Faceting)",
    "text": "1.8 Excercise 6 (Multiple little graphs/Faceting)\nStep 1: Read in Zillow Observed Rent Index (ZORI) data using read_csv('https://raw.githubusercontent.com/UI-Research/urbn101-intro-r/master/homework/zillow_clean.csv')\nStep 2: Clean the zillow data to just the most expensive ciites using code below:\nzillow_clean &lt;- zillow %&gt;%\n  arrange(desc(Avg_price)) %&gt;%\n  slice(1:10) %&gt;%\n  ggplot()+\n  geom_point(mapping=aes(x=Year, y=Avg_price))\nStep 3: In ggplot, plot the zillow_clean data as a scatter plot with year on the x axis and avg_price on the y axis.\nStep 4: Add facet_wrap(~RegionName) after the geom_point(mapping=aes(x=Year, y=Avg_price)) line."
  },
  {
    "objectID": "01_lesson.html#exercise-7-mapping",
    "href": "01_lesson.html#exercise-7-mapping",
    "title": "1  Data Visualization",
    "section": "1.9 Exercise 7 (Mapping)",
    "text": "1.9 Exercise 7 (Mapping)\nStep 1: Read in UFO sighting data (source: National UFO Reporting Center), link: https://raw.githubusercontent.com/UI-Research/urbn101-intro-r/master/homework/ufo_state.csv\nStep 1: Install urbnmapr devtools::install_github(\"UrbanInstitute/urbnmapr\"), load the urbnmapr library, and update the urbnthemes style to map set_urbn_defaults(style = \"map\").\nStep 2:: Pull a shapefile of US States using urbnmapr and join the UFO counts by state to the shapefile using the code below:\nstates_sf &lt;- get_urbn_map(\"states\", sf = TRUE)\n\nstates_ufo &lt;- states_sf %&gt;% \n  left_join(ufo, by=c(\"state_abbv\"=\"state\"))\nStep 3:: In ggplot, plot the states_ufo dataset, fill it in using the “count” column, add labels, change the outline (colour). Instead of using geom_point or geom_bar using geom_sf.\n Mapping Resources \n\nHow to Create State and County Maps Easily in R\nlibrary(urbnmapr)\nUrban Institute R Users Group website: mapping"
  },
  {
    "objectID": "01_lesson.html#functions",
    "href": "01_lesson.html#functions",
    "title": "1  Data Visualization",
    "section": "1.10 Functions",
    "text": "1.10 Functions\n\nggplot(): Create a plot, pull in data\naes(): The aesthetics that show up in the legend\ngeom_*(): What kind of graph\n\ngeom_point()\ngeom_line()\ngeom_bar()\ngeom_col()\ngeom_sf()\n\nscale_*(): The units on the x/y axis (discrete/continuous)\n\nscale_y_continuous()\n\nlabs(): Labels\n\nx/y/title/fill/colour"
  },
  {
    "objectID": "01_lesson.html#theory",
    "href": "01_lesson.html#theory",
    "title": "1  Data Visualization",
    "section": "1.11 Theory",
    "text": "1.11 Theory\n\nData\nAesthetic mappings\nGeometric objects\nScales\nCoordinate systems\nFacets\nStatistical transformations\nTheme"
  },
  {
    "objectID": "01_lesson.html#resources",
    "href": "01_lesson.html#resources",
    "title": "1  Data Visualization",
    "section": "1.12 Resources",
    "text": "1.12 Resources\n\nUrban Institute R Users Group website\nWhy the Urban Institute visualizes data with ggplot2\nR for Data Science: data visualization\nawunderground themes\nR Graph Gallery\n“A Layered Grammar of Graphics” by Hadley Wickham"
  },
  {
    "objectID": "02_lesson.html#review",
    "href": "02_lesson.html#review",
    "title": "2  Data Munging 1",
    "section": "2.1 Review",
    "text": "2.1 Review\n\nConsole/Environment/Script\nComment your code with # and read your error messages"
  },
  {
    "objectID": "02_lesson.html#assignment",
    "href": "02_lesson.html#assignment",
    "title": "2  Data Munging 1",
    "section": "2.2 Assignment",
    "text": "2.2 Assignment\n&lt;- is the assignment operator. An object created on the right side of an assignment operator is assigned to a name on the left side of an assignment operator. Assignment operators are important for saving the consequences of operations and functions. Without assignment, the result of a calculation is not saved for use in future calculations. Operations without assignment operators will typically be printed to the console but not saved for future use.\n\na &lt;- 1\nb &lt;- 2\n\nc &lt;- a + b\n\nc\n\n[1] 3"
  },
  {
    "objectID": "02_lesson.html#tidy-data",
    "href": "02_lesson.html#tidy-data",
    "title": "2  Data Munging 1",
    "section": "2.3 Tidy Data",
    "text": "2.3 Tidy Data\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ~ tidyverse.org\n\nlibrary(tidyverse) contains:\n\nggplot2, for data visualization.\ndplyr, for data manipulation.\ntidyr, for data tidying.\nreadr, for data import.\npurrr, for functional programming.\ntibble, for tibbles, a modern re-imagining of data frames.\nstringr, for strings.\nforcats, for factors.\n\n\n2.3.1 Tidy data\nThe defining opinion of the tidyverse is its wholehearted adoption of tidy data. Tidy data has three features:\n\nEach variable forms a column.\nEach observation forms a row.\nEach type of observational unit forms a dataframe. (This is from the paper, not the book)\n\n\nSource: R for data science\n\nTidy datasets are all alike, but every messy dataset is messy in its own way. ~ Hadley Wickham\n\nThe tidy approach to data science is powerful because it breaks data work into two distinct parts. First, get the data into a tidy format. Second, use tools optimized for tidy data. By standardizing the data structure for most community-created tools, the framework oriented diffuse development and reduced the friction of data work."
  },
  {
    "objectID": "02_lesson.html#exercise-0-creating-a-project-and-loading-packages",
    "href": "02_lesson.html#exercise-0-creating-a-project-and-loading-packages",
    "title": "2  Data Munging 1",
    "section": "2.4 Exercise 0: Creating a Project and Loading Packages",
    "text": "2.4 Exercise 0: Creating a Project and Loading Packages\nIf you are using a different computer or didn’t attend sessions 0 or 1, follow steps 1 and 2. If not- skip to step 3.\nStep 1: Open RStudio. File &gt; New Project &gt; New Directory &gt; Select the location where you would like to create a new folder that houses your R Project. Call it urbn101.\nStep 2: Open an .R script with the button in the top left (sheet with a plus sign icon). Save the script as 02_data-munging1.R.\nStep 3: If you have not previously installed library(tidyverse): submit install.packages(\"tidyverse\") to the Console (type and hit enter)\nWe’ll focus on the key dplyr syntax using the March 2020 Annual Social and Economic Supplement (ASEC) to the Current Population Survey (CPS). Run the following code to load the data.\nStep 4: Add and run the following code to load ASEC data.\n\nlibrary(tidyverse)\n\nasec &lt;- read_csv(\n  paste0(\n    \"https://raw.githubusercontent.com/awunderground/awunderground-data/\",\n    \"main/cps/cps-asec.csv\"\n  )\n)\n\nWe can use glimpse(asec) to quickly view the data. We can also use View(asec) to open up asec in RStudio.\n\n\nglimpse(x = asec)\n\nRows: 157,959\nColumns: 17\n$ year       &lt;dbl&gt; 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020,…\n$ serial     &lt;dbl&gt; 1, 1, 2, 2, 3, 4, 4, 5, 5, 5, 5, 7, 8, 9, 10, 10, 10, 12, 1…\n$ month      &lt;chr&gt; \"March\", \"March\", \"March\", \"March\", \"March\", \"March\", \"Marc…\n$ cpsid      &lt;dbl&gt; 2.01903e+13, 2.01903e+13, 2.01812e+13, 2.01812e+13, 2.01902…\n$ asecflag   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ asecwth    &lt;dbl&gt; 1552.90, 1552.90, 990.49, 990.49, 1505.27, 1430.70, 1430.70…\n$ pernum     &lt;dbl&gt; 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 4, 1, 1, 1, 1, 2, 3, 1, 2, 3,…\n$ cpsidp     &lt;dbl&gt; 2.01903e+13, 2.01903e+13, 2.01812e+13, 2.01812e+13, 2.01902…\n$ asecwt     &lt;dbl&gt; 1552.90, 1552.90, 990.49, 990.49, 1505.27, 1430.70, 1196.57…\n$ ftype      &lt;chr&gt; \"Primary family\", \"Primary family\", \"Primary family\", \"Prim…\n$ ftotval    &lt;dbl&gt; 127449, 127449, 64680, 64680, 40002, 8424, 8424, 59114, 591…\n$ inctot     &lt;dbl&gt; 52500, 74949, 44000, 20680, 40002, 0, 8424, 610, 58001, 503…\n$ incwage    &lt;dbl&gt; 52500, 56000, 34000, 0, 40000, 0, 8424, 0, 58000, 0, 0, 0, …\n$ offpov     &lt;chr&gt; \"Above Poverty Line\", \"Above Poverty Line\", \"Above Poverty …\n$ offpovuniv &lt;chr&gt; \"In Poverty Universe\", \"In Poverty Universe\", \"In Poverty U…\n$ offtotval  &lt;dbl&gt; 127449, 127449, 64680, 64680, 40002, 8424, 8424, 59114, 591…\n$ offcutoff  &lt;dbl&gt; 17120, 17120, 17120, 17120, 13300, 15453, 15453, 26370, 263…\n\n\n\nWe’re going to learn seven functions and one new piece of syntax from library(dplyr) that will be our main tools for manipulating tidy frames. These functions and a few extensions outlined in the Data Transformation Cheat Sheet are the core of data analysis in the Tidyverse."
  },
  {
    "objectID": "02_lesson.html#select",
    "href": "02_lesson.html#select",
    "title": "2  Data Munging 1",
    "section": "2.5 1. select()",
    "text": "2.5 1. select()\nselect() drops columns from a dataframe and/or reorders the columns in a dataframe. The arguments after the name of the dataframe should be the names of columns you wish to keep, without quotes. All other columns not listed are dropped.\n\n\nselect(.data = asec, year, month, serial)\n\n# A tibble: 157,959 × 3\n    year month serial\n   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n 1  2020 March      1\n 2  2020 March      1\n 3  2020 March      2\n 4  2020 March      2\n 5  2020 March      3\n 6  2020 March      4\n 7  2020 March      4\n 8  2020 March      5\n 9  2020 March      5\n10  2020 March      5\n# ℹ 157,949 more rows\n\n\n\nThis works great until the goal is to select 99 of 100 variables. Fortunately, - can be used to remove variables. You can also select all but multiple variables by listing them with the - symbol separated by commas.\n\n\nselect(.data = asec, -asecflag)\n\n# A tibble: 157,959 × 16\n    year serial month   cpsid asecwth pernum  cpsidp asecwt ftype ftotval inctot\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1  2020      1 March 2.02e13   1553.      1 2.02e13  1553. Prim…  127449  52500\n 2  2020      1 March 2.02e13   1553.      2 2.02e13  1553. Prim…  127449  74949\n 3  2020      2 March 2.02e13    990.      1 2.02e13   990. Prim…   64680  44000\n 4  2020      2 March 2.02e13    990.      2 2.02e13   990. Prim…   64680  20680\n 5  2020      3 March 2.02e13   1505.      1 2.02e13  1505. Nonf…   40002  40002\n 6  2020      4 March 2.02e13   1431.      1 2.02e13  1431. Prim…    8424      0\n 7  2020      4 March 2.02e13   1431.      2 2.02e13  1197. Prim…    8424   8424\n 8  2020      5 March 2.02e13   1133.      1 2.02e13  1133. Prim…   59114    610\n 9  2020      5 March 2.02e13   1133.      2 2.02e13  1133. Prim…   59114  58001\n10  2020      5 March 2.02e13   1133.      3 2.02e13  1322. Prim…   59114    503\n# ℹ 157,949 more rows\n# ℹ 5 more variables: incwage &lt;dbl&gt;, offpov &lt;chr&gt;, offpovuniv &lt;chr&gt;,\n#   offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;\n\n\n\n\n2.5.1 Exercise 1\n\nPromptSolution\n\n\n\nSelect pernum and inctot from asec.\n\n\n\n\nSelect pernum and inctot from asec.\n\n\nselect(.data = asec, inctot, asec)\n\n\n\n\n\\[\\cdots\\]"
  },
  {
    "objectID": "02_lesson.html#rename",
    "href": "02_lesson.html#rename",
    "title": "2  Data Munging 1",
    "section": "2.6 2. rename()",
    "text": "2.6 2. rename()\nrename() renames columns in a data frame. The pattern is new_name = old_name.\n\n\nrename(.data = asec, serial_number = serial)\n\n# A tibble: 157,959 × 17\n    year serial_number month   cpsid asecflag asecwth pernum  cpsidp asecwt\n   &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1  2020             1 March 2.02e13        1   1553.      1 2.02e13  1553.\n 2  2020             1 March 2.02e13        1   1553.      2 2.02e13  1553.\n 3  2020             2 March 2.02e13        1    990.      1 2.02e13   990.\n 4  2020             2 March 2.02e13        1    990.      2 2.02e13   990.\n 5  2020             3 March 2.02e13        1   1505.      1 2.02e13  1505.\n 6  2020             4 March 2.02e13        1   1431.      1 2.02e13  1431.\n 7  2020             4 March 2.02e13        1   1431.      2 2.02e13  1197.\n 8  2020             5 March 2.02e13        1   1133.      1 2.02e13  1133.\n 9  2020             5 March 2.02e13        1   1133.      2 2.02e13  1133.\n10  2020             5 March 2.02e13        1   1133.      3 2.02e13  1322.\n# ℹ 157,949 more rows\n# ℹ 8 more variables: ftype &lt;chr&gt;, ftotval &lt;dbl&gt;, inctot &lt;dbl&gt;, incwage &lt;dbl&gt;,\n#   offpov &lt;chr&gt;, offpovuniv &lt;chr&gt;, offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;\n\n\n\nYou can also rename a selection of variables using rename_with(). The .cols argument is used to select the columns to rename and takes a tidyselect statement like those we introduced above. Here, we’re using the where() selection helper which selects all columns where a given condition is TRUE. The default value for the .cols argument is everything() which selects all columns in the dataset.\n\n\nrename_with(.data = asec, .fn = toupper, .cols = where(is.numeric))\n\n# A tibble: 157,959 × 17\n    YEAR SERIAL month   CPSID ASECFLAG ASECWTH PERNUM  CPSIDP ASECWT ftype      \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1  2020      1 March 2.02e13        1   1553.      1 2.02e13  1553. Primary fa…\n 2  2020      1 March 2.02e13        1   1553.      2 2.02e13  1553. Primary fa…\n 3  2020      2 March 2.02e13        1    990.      1 2.02e13   990. Primary fa…\n 4  2020      2 March 2.02e13        1    990.      2 2.02e13   990. Primary fa…\n 5  2020      3 March 2.02e13        1   1505.      1 2.02e13  1505. Nonfamily …\n 6  2020      4 March 2.02e13        1   1431.      1 2.02e13  1431. Primary fa…\n 7  2020      4 March 2.02e13        1   1431.      2 2.02e13  1197. Primary fa…\n 8  2020      5 March 2.02e13        1   1133.      1 2.02e13  1133. Primary fa…\n 9  2020      5 March 2.02e13        1   1133.      2 2.02e13  1133. Primary fa…\n10  2020      5 March 2.02e13        1   1133.      3 2.02e13  1322. Primary fa…\n# ℹ 157,949 more rows\n# ℹ 7 more variables: FTOTVAL &lt;dbl&gt;, INCTOT &lt;dbl&gt;, INCWAGE &lt;dbl&gt;, offpov &lt;chr&gt;,\n#   offpovuniv &lt;chr&gt;, OFFTOTVAL &lt;dbl&gt;, OFFCUTOFF &lt;dbl&gt;\n\n\n\nMost dplyr functions can rename columns simply by prefacing the operation with new_name =. For example, this can be done with select():\n\n\nselect(.data = asec, year, month, serial_number = serial)\n\n# A tibble: 157,959 × 3\n    year month serial_number\n   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1  2020 March             1\n 2  2020 March             1\n 3  2020 March             2\n 4  2020 March             2\n 5  2020 March             3\n 6  2020 March             4\n 7  2020 March             4\n 8  2020 March             5\n 9  2020 March             5\n10  2020 March             5\n# ℹ 157,949 more rows"
  },
  {
    "objectID": "02_lesson.html#filter",
    "href": "02_lesson.html#filter",
    "title": "2  Data Munging 1",
    "section": "2.7 3. filter()",
    "text": "2.7 3. filter()\nfilter() reduces the number of observations in a dataframe. Every column in a dataframe has a name. Rows do not necessarily have names in a dataframe, so rows need to be filtered based on logical conditions.\n==, &lt;, &gt;, &lt;=, &gt;=, !=, %in%, and is.na() are all operators that can be used for logical conditions. ! can be used to negate a condition and & and | can be used to combine conditions. | means or.\n\n\n# return rows with pernum of 1 and incwage &gt; $100,000\nfilter(.data = asec, pernum == 1 & incwage &gt; 100000)\n\n# A tibble: 5,551 × 17\n    year serial month   cpsid asecflag asecwth pernum  cpsidp asecwt ftype      \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1  2020     28 March 2.02e13        1    678.      1 2.02e13   678. Primary fa…\n 2  2020    134 March 0              1    923.      1 0         923. Primary fa…\n 3  2020    136 March 2.02e13        1    906.      1 2.02e13   906. Primary fa…\n 4  2020    137 March 2.02e13        1   1493.      1 2.02e13  1493. Nonfamily …\n 5  2020    359 March 2.02e13        1    863.      1 2.02e13   863. Primary fa…\n 6  2020    372 March 2.02e13        1   1338.      1 2.02e13  1338. Primary fa…\n 7  2020    404 March 0              1    677.      1 0         677. Primary fa…\n 8  2020    420 March 2.02e13        1    747.      1 2.02e13   747. Primary fa…\n 9  2020    450 March 2.02e13        1   1309.      1 2.02e13  1309. Primary fa…\n10  2020    491 March 0              1   1130.      1 0        1130. Primary fa…\n# ℹ 5,541 more rows\n# ℹ 7 more variables: ftotval &lt;dbl&gt;, inctot &lt;dbl&gt;, incwage &lt;dbl&gt;, offpov &lt;chr&gt;,\n#   offpovuniv &lt;chr&gt;, offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;\n\n\nIPUMS CPS contains full documentation with information about pernum and incwage.\n\n\n2.7.1 Exercise 2\n\nPromptSolution\n\n\n\nFilter asec to rows with month equal to \"March\".\nFilter asec to rows with inctot less than 999999999.\nFilter asec to rows with pernum equal to 3 and inctot less than 999999999.\n\n\n\n\nFilter asec to rows with month equal to \"March\".\nFilter asec to rows with inctot less than 999999999.\nFilter asec to rows with pernum equal to 3 and inctot less than 999999999.\n\n\nfilter(asec, month == \"March\")\n\nfilter(asec, inctot &lt; 999999999)\n\nfilter(asec, pernum == 3, inctot &lt; 999999999)"
  },
  {
    "objectID": "02_lesson.html#arrange",
    "href": "02_lesson.html#arrange",
    "title": "2  Data Munging 1",
    "section": "2.8 4. arrange()",
    "text": "2.8 4. arrange()\narrange() sorts the rows of a data frame in alpha-numeric order based on the values of a variable or variables. The dataframe is sorted by the first variable first and each subsequent variable is used to break ties. desc() is used to reverse the sort order for a given variable.\n\n\n# sort pernum is descending order because high pernums are interesting\narrange(.data = asec, desc(pernum))\n\n# A tibble: 157,959 × 17\n    year serial month   cpsid asecflag asecwth pernum  cpsidp asecwt ftype      \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1  2020  91430 March 0              1    505.     16 0         604. Secondary …\n 2  2020  91430 March 0              1    505.     15 0         465. Secondary …\n 3  2020  91430 March 0              1    505.     14 0         416. Secondary …\n 4  2020  15037 March 2.02e13        1   2272.     13 2.02e13  2633. Primary fa…\n 5  2020  78495 March 0              1   1279.     13 0        1424. Related su…\n 6  2020  91430 March 0              1    505.     13 0         465. Secondary …\n 7  2020  15037 March 2.02e13        1   2272.     12 2.02e13  1689. Primary fa…\n 8  2020  18102 March 0              1   2468.     12 0        2871. Primary fa…\n 9  2020  22282 March 0              1   2801.     12 0        3879. Related su…\n10  2020  30274 March 2.02e13        1    653.     12 2.02e13   858. Primary fa…\n# ℹ 157,949 more rows\n# ℹ 7 more variables: ftotval &lt;dbl&gt;, inctot &lt;dbl&gt;, incwage &lt;dbl&gt;, offpov &lt;chr&gt;,\n#   offpovuniv &lt;chr&gt;, offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;\n\n\n\n\n2.8.1 Exercise 3\n\nPromptSolution\n\n\n\nSort asec in descending order by pernum and ascending order by inctot.\n\n\n\n\nSort asec in descending order by pernum and ascending order by inctot.\n\n\narrange(asec, desc(pernum), inctot)"
  },
  {
    "objectID": "02_lesson.html#mutate",
    "href": "02_lesson.html#mutate",
    "title": "2  Data Munging 1",
    "section": "2.9 5. mutate()",
    "text": "2.9 5. mutate()\nmutate() creates new variables or edits existing variables. We can use arithmetic arguments, such as +, -, *, /, and ^. We can also custom functions and functions from packages. For example, we can use library(stringr) for string manipulation and library(lubridate) for date manipulation.\n\nVariables are created by adding a new column name, like inctot_adjusted, to the left of = in mutate().\n\n# adjust inctot for underreporting\nmutate(.data = asec, inctot_adjusted = inctot * 1.1)\n\n# A tibble: 157,959 × 18\n    year serial month   cpsid asecflag asecwth pernum  cpsidp asecwt ftype      \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1  2020      1 March 2.02e13        1   1553.      1 2.02e13  1553. Primary fa…\n 2  2020      1 March 2.02e13        1   1553.      2 2.02e13  1553. Primary fa…\n 3  2020      2 March 2.02e13        1    990.      1 2.02e13   990. Primary fa…\n 4  2020      2 March 2.02e13        1    990.      2 2.02e13   990. Primary fa…\n 5  2020      3 March 2.02e13        1   1505.      1 2.02e13  1505. Nonfamily …\n 6  2020      4 March 2.02e13        1   1431.      1 2.02e13  1431. Primary fa…\n 7  2020      4 March 2.02e13        1   1431.      2 2.02e13  1197. Primary fa…\n 8  2020      5 March 2.02e13        1   1133.      1 2.02e13  1133. Primary fa…\n 9  2020      5 March 2.02e13        1   1133.      2 2.02e13  1133. Primary fa…\n10  2020      5 March 2.02e13        1   1133.      3 2.02e13  1322. Primary fa…\n# ℹ 157,949 more rows\n# ℹ 8 more variables: ftotval &lt;dbl&gt;, inctot &lt;dbl&gt;, incwage &lt;dbl&gt;, offpov &lt;chr&gt;,\n#   offpovuniv &lt;chr&gt;, offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;, inctot_adjusted &lt;dbl&gt;\n\n\n\nVariables are edited by including an existing column name, like inctot, to the left of = in mutate().\n\n# adjust income because of underreporting\nmutate(.data = asec, inctot = inctot * 1.1)\n\n# A tibble: 157,959 × 17\n    year serial month   cpsid asecflag asecwth pernum  cpsidp asecwt ftype      \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1  2020      1 March 2.02e13        1   1553.      1 2.02e13  1553. Primary fa…\n 2  2020      1 March 2.02e13        1   1553.      2 2.02e13  1553. Primary fa…\n 3  2020      2 March 2.02e13        1    990.      1 2.02e13   990. Primary fa…\n 4  2020      2 March 2.02e13        1    990.      2 2.02e13   990. Primary fa…\n 5  2020      3 March 2.02e13        1   1505.      1 2.02e13  1505. Nonfamily …\n 6  2020      4 March 2.02e13        1   1431.      1 2.02e13  1431. Primary fa…\n 7  2020      4 March 2.02e13        1   1431.      2 2.02e13  1197. Primary fa…\n 8  2020      5 March 2.02e13        1   1133.      1 2.02e13  1133. Primary fa…\n 9  2020      5 March 2.02e13        1   1133.      2 2.02e13  1133. Primary fa…\n10  2020      5 March 2.02e13        1   1133.      3 2.02e13  1322. Primary fa…\n# ℹ 157,949 more rows\n# ℹ 7 more variables: ftotval &lt;dbl&gt;, inctot &lt;dbl&gt;, incwage &lt;dbl&gt;, offpov &lt;chr&gt;,\n#   offpovuniv &lt;chr&gt;, offtotval &lt;dbl&gt;, offcutoff &lt;dbl&gt;\n\n\n\nConditional logic inside of mutate() with functions like if_else() and case_when() is key to mastering data munging in R.\n\n2.9.1 Exercise 4\n\nPromptSolution\n\n\n\nCreate a new variable called in_poverty. If offtotval is less than offcutoff then use \"Below Poverty Line\". Otherwise, use \"Above Poverty Line\". Hint: if_else() is useful and works like the IF command in Microsoft Excel.\n\n\n\n\nCreate a new variable called in_poverty. If offtotval is less than offcutoff then use \"Below Poverty Line\". Otherwise, use \"Above Poverty Line\". Hint: if_else() is useful and works like the IF command in Microsoft Excel.\n\n\nmutate(\n  asec,\n  in_poverty = if_else(\n    condition = offtotval &lt; offcutoff, \n    true = \"Below Poverty Line\", \n    false = \"Above Poverty Line\"\n  )\n)"
  },
  {
    "objectID": "02_lesson.html#section",
    "href": "02_lesson.html#section",
    "title": "2  Data Munging 1",
    "section": "2.10 %>%",
    "text": "2.10 %&gt;%\nData munging is tiring when each operation needs to be assigned to a name with &lt;-. The pipe, %&gt;%, allows lines of code to be chained together so the assignment operator only needs to be used once.\nConsider this fake code example from Hadley Wickham:\n\nI %&gt;% \n  tumble(out_of = \"bed\") %&gt;% \n  stumble(to = \"the kitchen\") %&gt;% \n  pour(who = \"myself\", unit = \"cup\", what = \"ambition\") %&gt;% \n  yawn() %&gt;% \n  stretch() %&gt;% \n  try(come_to_life())\n\n\n%&gt;% passes the output from function as the first argument in a subsequent function. For example, this line can be rewritten:\n\n\n# old way\nmutate(.data = asec, inctot_adjusted = inctot * 1.1)\n\n# new way\nasec %&gt;%\n  mutate(inctot_adjusted = inctot * 1.1)\n\n\nSee the power:\n\n\nnew_asec &lt;- asec %&gt;%\n  filter(pernum == 1) %&gt;%\n  select(year, month, pernum, inctot) %&gt;%\n  mutate(inctot_adjusted = inctot * 1.1) %&gt;%\n  select(-inctot)\n\nnew_asec\n\n# A tibble: 60,460 × 4\n    year month pernum inctot_adjusted\n   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;           &lt;dbl&gt;\n 1  2020 March      1          57750 \n 2  2020 March      1          48400 \n 3  2020 March      1          44002.\n 4  2020 March      1              0 \n 5  2020 March      1            671 \n 6  2020 March      1          19279.\n 7  2020 March      1          12349.\n 8  2020 March      1          21589.\n 9  2020 March      1          47306.\n10  2020 March      1          10949.\n# ℹ 60,450 more rows"
  },
  {
    "objectID": "02_lesson.html#summarize",
    "href": "02_lesson.html#summarize",
    "title": "2  Data Munging 1",
    "section": "2.11 6. summarize()",
    "text": "2.11 6. summarize()\nsummarize() collapses many rows in a dataframe into fewer rows with summary statistics of the many rows. n(), mean(), and sum() are common summary statistics. Renaming is useful with summarize()!\n\n\n# summarize without renaming the statistics\nasec %&gt;%\n  summarize(mean(ftotval), mean(inctot))\n\n# A tibble: 1 × 2\n  `mean(ftotval)` `mean(inctot)`\n            &lt;dbl&gt;          &lt;dbl&gt;\n1         105254.     209921275.\n\n# summarize and rename the statistics\nasec %&gt;%\n  summarize(\n    mean_ftotval = mean(ftotval), \n    mean_inctot = mean(inctot)\n  )\n\n# A tibble: 1 × 2\n  mean_ftotval mean_inctot\n         &lt;dbl&gt;       &lt;dbl&gt;\n1      105254.  209921275.\n\n\n\nsummarize() returns a data frame. This means all dplyr functions can be used on the output of summarize(). This is powerful! Manipulating summary statistics in Stata and SAS can be a chore. Here, it’s just another dataframe that can be manipulated with a tool set optimized for dataframes: dplyr."
  },
  {
    "objectID": "02_lesson.html#group_by",
    "href": "02_lesson.html#group_by",
    "title": "2  Data Munging 1",
    "section": "2.12 7. group_by()",
    "text": "2.12 7. group_by()\ngroup_by() groups a dataframe based on specified variables. summarize() with grouped dataframes creates subgroup summary statistics. mutate() with group_by() calculates grouped summaries for each row.\n\n\nasec %&gt;%\n  group_by(pernum) %&gt;%\n  summarize(\n    n = n(),\n    mean_ftotval = mean(ftotval), \n    mean_inctot = mean(inctot)\n  )\n\n# A tibble: 16 × 4\n   pernum     n mean_ftotval mean_inctot\n    &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1      1 60460       94094.      57508.\n 2      2 45151      108700.   77497357.\n 3      3 25650      117966.  473030618.\n 4      4 15797      121815.  634999933.\n 5      5  6752      108609.  691504650.\n 6      6  2582       89448.  682810446.\n 7      7   922       78889.  682218196.\n 8      8   353       72284.  682725646.\n 9      9   158       54599.  632917559.\n10     10    73       58145.  657543632.\n11     11    37       61847.  702708584 \n12     12    18       50249.  777780725.\n13     13     3       25152   666666666 \n14     14     1       18000       18000 \n15     15     1       25000       25000 \n16     16     1       15000       15000 \n\n\n\nDataframes can be grouped by multiple variables.\nGrouped tibbles include metadata about groups. For example, Groups:   pernum, offpov [40]. One grouping is dropped each time summarize() is used. It is easy to forget if a dataframe is grouped, so it is safe to include ungroup() at the end of a section of functions.\n\n\nasec %&gt;%\n  group_by(pernum, offpov) %&gt;%\n  summarize(\n    n = n(),\n    mean_ftotval = mean(ftotval), \n    mean_inctot = mean(inctot)\n  ) %&gt;%\n  arrange(offpov) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'pernum'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 40 × 5\n   pernum offpov                 n mean_ftotval mean_inctot\n    &lt;dbl&gt; &lt;chr&gt;              &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1      1 Above Poverty Line 53872      104451.      63642.\n 2      2 Above Poverty Line 40978      118691.   59082162.\n 3      3 Above Poverty Line 23052      129891.  463440562.\n 4      4 Above Poverty Line 14076      135039.  631720097.\n 5      5 Above Poverty Line  5805      123937.  688206447.\n 6      6 Above Poverty Line  2118      105867.  683199297.\n 7      7 Above Poverty Line   724       96817.  697520661.\n 8      8 Above Poverty Line   269       90328.  672870019.\n 9      9 Above Poverty Line   114       70438.  622815186.\n10     10 Above Poverty Line    57       71483.  666678408.\n# ℹ 30 more rows\n\n\n\n\n2.12.1 Exercise 5\n\nPromptSolution\n\n\n\nfilter() to only include observations with \"In Poverty Universe\" in offpovuniv.\ngroup_by() offpov.\nUse summarize() and n() to count the number of observations in poverty.\n\n\n\n\nfilter() to only include observations with \"In Poverty Universe\" in offpovuniv.\ngroup_by() offpov.\nUse summarize() and n() to count the number of observations in poverty.\n\n\nasec %&gt;%\n  filter(offpovuniv == \"In Poverty Universe\") %&gt;%\n  group_by(offpov) %&gt;%\n  summarize(n())\n\n\n\n\n\n\n2.12.2 Exercise 6\n\nPromptSolution\n\n\n\nfilter() to only include observations with \"In Poverty Universe\".\ngroup_by() cpsid.\nUse mutate(family_size = n()) to calculate the family size for each observation in asec.\nungroup()\ngroup_by() family_size, and offpov.\nUse summarize() and n() to see how many families of each size are experiencing poverty.\n\n\n\n\nfilter() to only include observations with \"In Poverty Universe\".\ngroup_by() cpsid.\nUse mutate(family_size = n()) to calculate the family size for each observation in asec.\nungroup()\ngroup_by() family_size, and offpov.\nUse summarize() and n() to see how many families of each size are experiencing poverty.\n\n\nasec %&gt;%\n  filter(offpovuniv == \"In Poverty Universe\") %&gt;%\n  group_by(cpsid) %&gt;%\n  mutate(family_size = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(family_size, offpov) %&gt;%\n  summarize(n())\n\n\n\n\nAre the estimates from the previous two exercises correct?\nLet’s look at a Census Report to see how many people were in poverty in 2019. We estimated about 16,500 people. The Census Bureau says 34.0 million people.\nNo! We did not account for sampling weights, so our estimates are incorrect. library(srvyr) has tools for weighted estimation with complex surveys."
  },
  {
    "objectID": "02_lesson.html#resources",
    "href": "02_lesson.html#resources",
    "title": "2  Data Munging 1",
    "section": "2.13 Resources",
    "text": "2.13 Resources\n\nR for Data Science: data transformation\nData wrangling cheat sheet"
  },
  {
    "objectID": "03_lesson.html#review",
    "href": "03_lesson.html#review",
    "title": "3  Data Munging 2",
    "section": "3.1 Review",
    "text": "3.1 Review\n\n%&gt;%: The pipe operator\ndplyr verbs for data manipulation\n\nselect()\nfilter()\nrename()\narrange()\nmutate()\nsummarize()\ngroup_by()"
  },
  {
    "objectID": "03_lesson.html#motivation",
    "href": "03_lesson.html#motivation",
    "title": "3  Data Munging 2",
    "section": "3.2 Motivation",
    "text": "3.2 Motivation\n\nReview and master library(dplyr)\nExpand our skill set so we can do more types of analysis\n\n\n3.2.1 Exercise 0\nStep 1: Open up your .Rproj for urbn101. You should now see urbn101 in the top right of RStudio instead of “Project: (None)” .\nStep 2: Install the R package nycflights13.\nStep 3: Load tidyverse and nycflights13 at the top of your script.\nStep 4: Run data(flights) in the console to load the flights data set into your R environment. Also run data(planes) to load the planes data set.\nStep 5: Look at the flights data set (how many ways can you do this?)"
  },
  {
    "objectID": "03_lesson.html#conditional-transformation",
    "href": "03_lesson.html#conditional-transformation",
    "title": "3  Data Munging 2",
    "section": "3.3 Conditional transformation",
    "text": "3.3 Conditional transformation\nLast week, we showed how mutate() can be used to create new variables or to transform new variables. We also learned about if_else()m which works great for one condition.\nBut what if you have multiple conditions? case_when() allows for a sequence of conditional logic that can be used to transform or create variables with mutate(). For example, here I create a variable called lateness that creates a character variable with the levels \"very late\", \"late\", and \"on time\". The logic is evaluated from top to bottom and TRUE is used to refer to all other remaining cases.\nThe syntax may look a little weird at first but it’s easy to pick up! The logical condition goes to the left of ~ and the output results goes to the right. & and | can be used to combine logical statements.\n\nflights %&gt;%\n  mutate(\n    lateness = case_when(\n      arr_delay &gt; 30 ~ \"very late\",\n      arr_delay &gt; 0 ~ \"late\",\n      TRUE          ~ \"on time\"\n    )\n  )\n\n\n3.3.1 Exercise 1\n\nPromptSolution\n\n\n\nLook at the planes data. We want to create a categorical variables called plane_type using the following rules for the variable seats:\n\n\n“personal” if the plane has 4 or fewer seats\n“commercial” if the plane has 5 to 199 seats\n“jumbo if the plane has more than 200 seats\n\n\nUse mutate() and case_when() to create seats.\nPipe into count(plane_tyepe).\n\n\n\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nplanes %&gt;%\n  mutate(\n    plane_type = case_when(\n      seats &lt;= 4   ~ \"personal\",\n      seats &lt;= 199 ~ \"commercial\",\n      TRUE         ~ \"jumbo\"\n    )\n  ) %&gt;%\n  count(plane_type)\n\n# A tibble: 3 × 2\n  plane_type     n\n  &lt;chr&gt;      &lt;int&gt;\n1 commercial  2750\n2 jumbo        551\n3 personal      21"
  },
  {
    "objectID": "03_lesson.html#strings",
    "href": "03_lesson.html#strings",
    "title": "3  Data Munging 2",
    "section": "3.4 Strings",
    "text": "3.4 Strings\nlibrary(stringr) contains powerful and concise functions manipulating character variables. Reference the cheat sheet for an overview of the different string maniuplation functions.\n\n3.4.1 Exercise 2\nThe month and day columns in flights are currently integer variables. We want to turn them into character variables with leading zeros. For example, 1 should be \"01\".\n\nPromptSolution\n\n\nStep 1: Use mutate() to overwrite month and day with str_pad(). The first argument should be month or day. The second argument, width, should be 2.\nStep 2: The padding character is currently a space, but we want it to be \"0\". Use ?str_pad to figure out how to switch the padding character.\nStep 3: Pipe the result into the following line mutate(flight_date = paste(year, month, day, sep = \"-\"))\nStep 4: Drop all variables except flight_date, distance, and air_time.\nStep 5: Assign the result to flights_subset.\n\n\n\nflights_subset &lt;- flights %&gt;%\n  mutate(\n    month = str_pad(month, width = 2, side = \"left\", pad = \"0\"),\n    day = str_pad(day, width = 2, side = \"left\", pad = \"0\")\n  ) %&gt;%\n  mutate(flight_date = paste(year, month, day, sep = \"-\")) %&gt;%\n  select(flight_date, distance, air_time)"
  },
  {
    "objectID": "03_lesson.html#dates",
    "href": "03_lesson.html#dates",
    "title": "3  Data Munging 2",
    "section": "3.5 Dates",
    "text": "3.5 Dates\nlibrary(lubridate) contains powerful and concise functions for creating and manipulating dates, times, and date-times. It is aware of leap days and leap seconds and is useful for calculating periods, durations, intervals, and more.\n\n3.5.1 Exercise 3\n\nPromptSolution\n\n\nStep 1: Add library(lubridate) after library(nycflight13) in your script.\nStep 2: library(lubridate) is powerful but it needs variables in the correct format. Use ymd() inside of mutate() to turn the flight_date variable into a date rather than a character vector.\nStep 3: Inside the previous mutate statement, add another column called weekday for the weekday of the flight. You can use wday(flight_date) to find the day of the week for each date.\nStep 4: Assign the result to flights_subset.\nStep 5: Use count() to count the number of flights by day of the week.\n\n\n\nlibrary(lubridate)\n\nflights_subset &lt;- flights_subset %&gt;%\n  mutate(flight_date = ymd(flight_date)) %&gt;%\n  mutate(weekday = wday(flight_date, label = TRUE)) \n\nflights_subset %&gt;%\n  count(weekday)\n\n# A tibble: 7 × 2\n  weekday     n\n  &lt;ord&gt;   &lt;int&gt;\n1 Sun     46357\n2 Mon     50690\n3 Tue     50422\n4 Wed     50060\n5 Thu     50219\n6 Fri     50308\n7 Sat     38720"
  },
  {
    "objectID": "03_lesson.html#group_by-and-summarize",
    "href": "03_lesson.html#group_by-and-summarize",
    "title": "3  Data Munging 2",
    "section": "3.6 group_by and summarize()",
    "text": "3.6 group_by and summarize()\n\n3.6.1 Exercise 4\nWe are going to summarize flights_subset from the previous example by weekday.\n\nPromptSolution\n\n\nStep 1: group_by() weekday and use n() in summarize() to count the number of observations. This should match Step 5 from the previous exercise.\nStep 2: In the same summarize(), calculate mean(), and max() distance.\nStep 3: In the same summarize(), calculate median air_time.\nStep 4: Rename the resulting variables inside summarize() so they have more useful names.\n\n\n\nflights_subset %&gt;%\n  group_by(weekday) %&gt;%\n  summarize(\n    n(),\n    mean_distance = mean(distance),\n    max_distance = max(distance),\n    median_air_time = median(air_time, na.rm = TRUE)\n  )\n\n# A tibble: 7 × 5\n  weekday `n()` mean_distance max_distance median_air_time\n  &lt;ord&gt;   &lt;int&gt;         &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt;\n1 Sun     46357         1055.         4983             130\n2 Mon     50690         1032.         4983             129\n3 Tue     50422         1027.         4983             128\n4 Wed     50060         1028.         4983             128\n5 Thu     50219         1033.         4983             128\n6 Fri     50308         1033.         4983             127\n7 Sat     38720         1081.         4983             134"
  },
  {
    "objectID": "03_lesson.html#left_join",
    "href": "03_lesson.html#left_join",
    "title": "3  Data Munging 2",
    "section": "3.7 left_join()",
    "text": "3.7 left_join()\nJoins are the main method for combining two datasets with a commmon key column together. There are many types of joins, and we highly recommend you read this chapter on joins in R4DS if you want more info. Below is a quick visual summary of the types of joins you can perform in R. \nFor now we will focus on the “left” join, which merges observations from the right data set to the left data set. This is the join type I use 90% of the time in R. Below is an example of how the left_join() function works.\n\npeople &lt;- tribble(\n  ~name, ~team, \n  \"Aaron\", \"Pacers\",\n  \"Kyle\", \"Wizards\",\n  \"Ajjit\", \"Warriors\",\n  \"Fay\", \"Wizards\"\n)\n\nteam_locations &lt;- tribble(\n  ~team, ~city,\n  \"Warriors\", \"Oakland\",\n  \"Pacers\", \"Indianoplis\",\n  \"Wizards\", \"Washington DC\"\n)\n\nleft_join(\n  x = people,\n  y = team_locations, \n  by = \"team\"\n)\n\n# A tibble: 4 × 3\n  name  team     city         \n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;        \n1 Aaron Pacers   Indianoplis  \n2 Kyle  Wizards  Washington DC\n3 Ajjit Warriors Oakland      \n4 Fay   Wizards  Washington DC\n\n\n\n3.7.1 Exercise 5\nflights contains information about flights and the unit of observation is airplane flights. planes contains information about the airplanes and the unit of observation is the airplane. The common column between these tables is the tailnum column.\nWe want to add information about planes to the flights data set. This is a left join because for every flight in the dataset, we want to append flight information. This is also called a many-to-one join because we are joining many rows from the flights data to one row from the planes data.\n\nPromptSolution\n\n\nStep 1: Use left_join() to join planes to flights. The common key is tailnum.\nStep 2: Use anti_join() to see observations from flights that don’t have a match in planes and call the output object unmatched_flights. The common key is tailnum.\nStep 2: Use slice() and pull() to extract the tailnum value in the first row of unmatched_flights. Call this variable first_unmatched_tailnum\nStep 3: Use filter() to see if first_unmatched_tailnum is in planes. Hint: it shouldn’t be!\n\n\n\nleft_join(\n  x = flights,\n  y = planes,\n  by = \"tailnum\"\n)\n\n# A tibble: 336,776 × 27\n   year.x month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1   2013     1     1      517            515         2      830            819\n 2   2013     1     1      533            529         4      850            830\n 3   2013     1     1      542            540         2      923            850\n 4   2013     1     1      544            545        -1     1004           1022\n 5   2013     1     1      554            600        -6      812            837\n 6   2013     1     1      554            558        -4      740            728\n 7   2013     1     1      555            600        -5      913            854\n 8   2013     1     1      557            600        -3      709            723\n 9   2013     1     1      557            600        -3      838            846\n10   2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 19 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, year.y &lt;int&gt;, type &lt;chr&gt;,\n#   manufacturer &lt;chr&gt;, model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;,\n#   engine &lt;chr&gt;\n\nfirst_unmatched_tailnum &lt;- anti_join(\n  x = flights,\n  y = planes,\n  by = \"tailnum\"\n) %&gt;%\n  slice(1) %&gt;%\n  pull(tailnum)\n\nplanes %&gt;%\n  filter(tailnum == first_unmatched_tailnum)\n\n# A tibble: 0 × 9\n# ℹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;"
  },
  {
    "objectID": "03_lesson.html#custom-functions",
    "href": "03_lesson.html#custom-functions",
    "title": "3  Data Munging 2",
    "section": "3.8 Custom functions",
    "text": "3.8 Custom functions\nSometimes functions don’t exist for desired calculations or we want to combine many calculations into one function to reduce copying-and-pasting.\n“You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).” ~ R4DS\nR has a flexible function system that makes it very easy to define custom functions!\n\nfunction_name &lt;- function(arg1, arg2 = default) {\n\n  # function body\n\n}\n\nThree ingredients\n\nFunction name - usually verbs\nFunction arguments - inputs to the function (optional)\nFunction body\n\n\nsquare &lt;- function(x = 2) {\n  x ^ 2\n}\n\nsquare()\n\n[1] 4\n\nsquare(x = 4)\n\n[1] 16\n\n\nNote: Using tidyverse functions inside of custom functions often requires non-standard evaluation. Please reach out for help when this is your goal.\n\n3.8.1 Exercise 6\n\nPromptSolution\n\n\nStep 1: Write a function called multiply_xy() that takes arguments x and y and multiplies them together.\nStep 2: Add your favorite number as the default for x and your least favorite number as the default for y.\nStep 3: Call the function and overwrite the default for y with your favorite number.\n\n\n\nmultiply_xy &lt;- function(x = 3.14, y = 7) {\n  \n  x * y\n  \n}\n\nmultiply_xy(y = 3.14) \n\n[1] 9.8596"
  },
  {
    "objectID": "03_lesson.html#resources",
    "href": "03_lesson.html#resources",
    "title": "3  Data Munging 2",
    "section": "3.9 Resources",
    "text": "3.9 Resources\n\nR4DS: functions\nstringr cheat sheet"
  },
  {
    "objectID": "04_lesson.html#review",
    "href": "04_lesson.html#review",
    "title": "4  Data Import",
    "section": "4.1 Review",
    "text": "4.1 Review\n\nWhat is tidy data?\n\nArtwork by @allison_horst\nWhat is a file path?\nWhat is an R Studio Project?\nStay DRY: if you find yourself copying and pasting chunks of code, write a function instead.\nWriting functions that use capabilities of the tidyverse can be tricky due to something called Nonstandard Evaluation - feel free to ask any of us for help!"
  },
  {
    "objectID": "04_lesson.html#motivation",
    "href": "04_lesson.html#motivation",
    "title": "4  Data Import",
    "section": "4.2 Motivation",
    "text": "4.2 Motivation\n\ndiamonds, storms, or starwars are nice examples, but how do I load data for an actual research project?\nData import is a crucial yet often overlooked step of truly replicable and reproducible research."
  },
  {
    "objectID": "04_lesson.html#packages",
    "href": "04_lesson.html#packages",
    "title": "4  Data Import",
    "section": "4.3 Packages",
    "text": "4.3 Packages\nWe’ll be using three packages from the tidyverse for data import and export. These three should cover just about all of your use cases at Urban.\n\nreadr - for plain text files (.csv, .tsv)\nreadxl - for Excel files (.xlsx, .xls)\nhaven - for SAS (.sas7bdat + .sas7bcat files), SPSS (.sav files), and Stata (.dta files up to Stata version 17) formats\n\nOne note - while all three packages are installed with the tidyverse, only readr is loaded when you run library(tidyverse) in your R session. The other packages must be loaded separately."
  },
  {
    "objectID": "04_lesson.html#primary-functions",
    "href": "04_lesson.html#primary-functions",
    "title": "4  Data Import",
    "section": "4.4 Primary Functions",
    "text": "4.4 Primary Functions\nIn general, readr, readxl, and haven will come with some variant of a read function for data import, and a variant of write (except for Excel and SAS!) for data export.\n\nreadr::read_csv(), readr::write_csv()\nreadr::read_delim(), readr::write_delim()\nreadxl::read_excel()\nhaven::read_sas()\nhaven::read_dta(), haven::write_dta\n\nFor the simplest use cases, the various read functions will need just one argument: the path to the file you want to load.\n\ndf &lt;- read_csv(\"path/to/your/original/data.csv\")\n\nThe various write functions will need two arguments: the data frame you want to export, and the file path to save it to.\n\nwrite_csv(df, \"path/to/your/modified/data.csv\")"
  },
  {
    "objectID": "04_lesson.html#setup",
    "href": "04_lesson.html#setup",
    "title": "4  Data Import",
    "section": "4.5 Setup",
    "text": "4.5 Setup\n\n4.5.1 Exercise\nStep 1: Open up your RStudio project, open a R script, save it with a meaningful name, and load the tidyverse, readxl, haven, and arrow.\nStep 2: Use the dir.create() function to create subfolders called data and modified in your R Project.\nStep 3: We’ll be downloading a couple different datasets for today’s examples. Staying DRY, let’s rework the example code from Wednesday into a function we can reuse. Copy and paste the following into your file. Make sure to run the code so the function becomes a part of your environment.\n\ndownload_data &lt;- function(url, path) {\n  if (!file.exists(path)) {\n    download.file(url, path, mode = \"wb\")\n  }\n}"
  },
  {
    "objectID": "04_lesson.html#the-readr-package",
    "href": "04_lesson.html#the-readr-package",
    "title": "4  Data Import",
    "section": "4.6 The readr Package",
    "text": "4.6 The readr Package\nreadr provides functions to read plain text rectangular data - think csv, txt or tsv files.\n\n4.6.1 CSV Files\n\n4.6.1.1 Example\nFirst we’ll download an example csv file from the Urban Institute’s Education data portal:\n\n# Download ipeds data into data/ folder\ndownload_data(\"https://educationdata.urban.org/csv/ipeds/colleges_ipeds_completers.csv\",\n              \"data/colleges_ipeds_completers.csv\")\n\nAnd then use read_csv from the readr package to load the data in.\n\nipeds &lt;- read_csv(\"data/colleges_ipeds_completers.csv\")\n\nWe now have a tibble that can be used with all the ggplot2 and dplyr functions you’ve learned so far. Let’s filter the data to only 2011 and write it out as a separate file:\n\nipeds_2011 &lt;- ipeds %&gt;%\n  filter(year == 2011)\n\nwrite_csv(ipeds_2011, \"modified/colleges_ipeds_completers_2011.csv\")\n\n\n\n4.6.1.2 Exercise\nStep 1: Filter the ipeds data frame to years 2014-2015 for the state of California (HINT: fips code of 6). Be sure to use &lt;- to save it to a new object!\nStep 2: Write the filtered data frame to a file called “ipeds_completers_ca.csv” in your modified folder.\n\n\n\n4.6.2 Other Delimiters\nMost plain text files will use a comma to separate values. Sometimes you’ll see other delimiters used - the most common are tabs \\t and vertical bar | (which is often called a pipe, not to be confused with the tidyverse pipe %&gt;%).\nTo read in a plain text file that uses another delimiter, use the read_delim function. This function will take two arguments: the path to the file you want to load and the character to use as a delimiter.\n\n4.6.2.1 Example\nFirst we’ll download a tab delimited file from the North Carolina Board of Elections:\n\ndownload_data(\"https://s3.amazonaws.com/dl.ncsbe.gov/data/ncvhis30.zip\",\n              \"data/ncvhis30.zip\")\n\nThen load in the file with the correct delimiter set. It may be helpful to open delimtied file with a program like Notepad so you can see the plain text in the file and decide what delimiter to use. In this case we know its a tab:\n\nncvhis &lt;- read_delim(\"data/ncvhis30.zip\", delim = \"\\t\")\n\nNote that readr was able to read the data directly from the zipfile!\nSimilarly, the write_delim() function can be used to write out a plain text file with a specified delim argument.\n\n\n4.6.2.2 Exercise\nStep 1: Use write_delim() to write out ncvhis to a pipe | separated file.\n\n\n\n4.6.3 Common Issues\nNot all data import will be quick and easy. Often times you will run into issues - these can be daunting at first but are often not as bad as they seem.\n\n4.6.3.1 Example\nThe readr package provides a challenge.csv file that will throw numerous parsing issues.\n\nchallenge &lt;- read_csv(readr_example(\"challenge.csv\"))\n\nYou can use the problems function to get a tibble of these issues.\n\nissues &lt;- problems(challenge)\n\nA thousand parsing failures sounds like a lot! But it’s really just one error a thousand times, and not a thousand unique errors to work through.\nThe issue is that readr will read the first thousand lines of a file and use that as the column specification. This file changes data types at line 1001. This is a very common issue when reading text files into R. We can use the guess_max argument to increase the number of lines readr will use to set the column types.\n\nchallenge &lt;- read_csv(readr_example(\"challenge.csv\"),\n                      guess_max = Inf)\n\nYou will run into other problems when importing data like:\n\nthe columns not being in the first row\nweird NA values\nblank rows at the top of files\n\nLuckily read_csv() and its friends have a lot of built in arguments to help deal with those issues. Look at the arguments in the docs using ?read_csv or go to the R4DS data import page for examples of how to deal with all the above problems.\n\n\n\n4.6.4 Exercise\nStep 1: Pull up the documentation for read_csv and take a look of some of the function arguments. There are a lot! You don’t need to know how everything works, but it’s good to have an idea of some of the options available to you."
  },
  {
    "objectID": "04_lesson.html#the-readxl-package",
    "href": "04_lesson.html#the-readxl-package",
    "title": "4  Data Import",
    "section": "4.7 The readxl Package",
    "text": "4.7 The readxl Package\nFor data that is saved as .xls or .xlsx, use the readxl package.\n\n4.7.1 Example\nFor this example we’ll download data from the HUD FHA Single Family Portfolio Snap Shot.\n\ndownload_data(\"https://www.hud.gov/sites/dfiles/Housing/documents/FHA_SFSnapshot_Apr2019.xlsx\",\n              \"data/sfsnap.xlsx\")\n\nThis Excel file contains a number of tables on different sheets of the workbook. We can see a listing of the sheets using the excel_sheets function. As usual, the first argument is the path to the data file.\n\nexcel_sheets(\"data/sfsnap.xlsx\")\n\nWe can then use the read_excel function to load our data into our R session. Again, the first argument is the path to the .xlsx file. We also use the sheet argument to specify which sheet of the workbook we want.\n\npurchases &lt;- read_excel(\"data/sfsnap.xlsx\", sheet = \"Purchase Data April 2019\")\n\nNote that the readxl package only provides functionality to, as the name implies, read Excel files. If you need to write your data out to .xls or .xlsx formats - don’t! We highly recommend saving data files as .csv files wherever possible. But if you you really need to, look into the writexl or openxlsx packages.\n\n\n4.7.2 Exercise\nStep 1: Use read_excel() to load in the table on the “Refinance Data April 2019” sheet into a data frame called refinances."
  },
  {
    "objectID": "04_lesson.html#the-haven-package",
    "href": "04_lesson.html#the-haven-package",
    "title": "4  Data Import",
    "section": "4.8 The haven Package",
    "text": "4.8 The haven Package\nFinally, your SAS, SPSS, or Stata data can find safe haven in R.\n\n4.8.1 Stata Data (.dta)\n\n4.8.1.1 Example\nFirst we’ll download and unzip the 2018 General Social Survey, which comes as a zipped .dta file.\n\ndownload_data(\"http://gss.norc.org/Documents/stata/2018_stata.zip\",\n              \"data/gss.zip\")\n\nunzip(\"data/gss.zip\", exdir = \"data/\")\n\nTo read a .dta file, we’ll use the aptly named read_dta function. As usual, the first argument to the function is the path to the data we want to import.\n\ngss &lt;- read_dta(\"data/GSS2018.dta\")\n\n# We can also read in the zip file directly!\ngss &lt;- read_dta(\"data/gss.zip\")\n\n\n\n\n4.8.2 SAS Data (.sas7bdat)\nWe use read_sas to read in SAS files. This works mostly identical to read_stata, and you can read in .sas7bdat + .sas7bcat, or zipped folders with sas files. Note that while the write_sas() function exists, it doesn’t appear to actually work at the current version of haven.\n\n4.8.2.1 Example\nDownload and read in the 2017 1-year Public Use Microsample for Wyoming from the Census:\n\ndownload_data(\"https://www2.census.gov/programs-surveys/acs/data/pums/2017/1-Year/unix_pwy.zip\",\n              \"data/pums_wy.zip\")\n\n# Unzip the files\nunzip(\"data/pums_wy.zip\", exdir = \"data/\")\n\n# Read in sas file\npums_data = read_sas(\"data/pums_wy.zip\")\n\n# Write out as dta file\npums_data %&gt;% write_dta(\"modified/pums_wy.dta\")"
  },
  {
    "objectID": "04_lesson.html#the-arrow-package",
    "href": "04_lesson.html#the-arrow-package",
    "title": "4  Data Import",
    "section": "4.9 The arrow Package",
    "text": "4.9 The arrow Package\nSometimes when you save text files, the column types (ie numeric, date, time, text, etc.) get lost and won’t be read back in upon reimporting In this case you may want to save your files as a binary file. One binary file format we suggest is .feather files, which you can read more about. The main benefits of storing data in a binary format is:\n\nColumn types will be recorded and preserved\nImporting and exporting will be faster than other methods\nFile sizes will be smaller as binary files often use compression methods\n\nThe cons are that:\n\n.feather files can only easily be read into R and python currently\nThere are no nice GUI viewers (like Excel/Notepad for CSV data) to actually “see” the data files\n\nSo think before exercising this option! If you mainly will be working with your data in R and have large file sizes or complicated column types, .feather files may be a good option.\nYou can read and write these files with read_feather() and write_feather respectively.\n\n# Write out a feather file to `modified/folder`\nwrite_feather(ipeds_2011, \"modified/colleges_ipeds_completers_2011.feather\")\n\n# Read in a feather file\nipeds_2011 = read_feather(\"modified/colleges_ipeds_completers_2011.feather\")"
  },
  {
    "objectID": "04_lesson.html#resources",
    "href": "04_lesson.html#resources",
    "title": "4  Data Import",
    "section": "4.10 Resources",
    "text": "4.10 Resources\n\nR4DS: Data import\nData Import Cheatsheet"
  },
  {
    "objectID": "05_lesson.html#review",
    "href": "05_lesson.html#review",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.1 Review",
    "text": "5.1 Review\n\nThe tidyverse contains three packages that should handle almost all of your data import needs:\n\nreadr - for plain text files (read_csv(), write_csv())\nreadxl - for Excel files (read_excel())\nhaven - for SAS, SPSS, and Stata data formats (read_dta(), read_sas(), write_dta())\n\nDon’t use haven::write_sas() to try to create a sas7bdat file!\nTidy data"
  },
  {
    "objectID": "05_lesson.html#motivation",
    "href": "05_lesson.html#motivation",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.2 Motivation",
    "text": "5.2 Motivation\n\nYou want to apply a transformation to all variables in a data frame (or a subset of them).\nYou want to summarize many variables, create many statistics for one variable, or some combination of the two.\nYou want to read in many different .csv files."
  },
  {
    "objectID": "05_lesson.html#vectorization",
    "href": "05_lesson.html#vectorization",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.3 Vectorization",
    "text": "5.3 Vectorization\nThere is less need to write code for control flow in R. First, everything is vectorized so there is rarely a need to iterate to manipulate a vector.\n\n1:10 * 2\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\n\ndiamonds %&gt;%\n  select(carat, price) %&gt;%\n  mutate(price_canadian = price * 1.31)\n\n# A tibble: 53,940 × 3\n   carat price price_canadian\n   &lt;dbl&gt; &lt;int&gt;          &lt;dbl&gt;\n 1  0.23   326           427.\n 2  0.21   326           427.\n 3  0.23   327           428.\n 4  0.29   334           438.\n 5  0.31   335           439.\n 6  0.24   336           440.\n 7  0.24   336           440.\n 8  0.26   337           441.\n 9  0.22   337           441.\n10  0.23   338           443.\n# ℹ 53,930 more rows"
  },
  {
    "objectID": "05_lesson.html#across",
    "href": "05_lesson.html#across",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.4 across()",
    "text": "5.4 across()\nOn Day 2 we introduced a number of dplyr functions:\n\nmutate(): to transform a variable\nselect(): to subset the columns of a data frame\nfilter(): to subset the rows of a data frame\nsummarise(): to calculate summary statistics\ngroup_by(): to perform an operation by group\n\nSometimes we will want to apply these functions many times. For example, what if we want to manipulate many variables. For this, we will use the new across() function. To demonstrate across(), we’ll use the built-in mtcars data frame:\n\nlibrary(tidyverse)\n\nmtcars &lt;- as_tibble(mtcars)\nhead(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\n\n\n\n5.4.1 mutate()\nSay we wanted to round all the variables of this data frame. We could write some very repetitive code:\n\nmtcars %&gt;%\n  mutate(\n    mpg = round(mpg),\n    cyl = round(cyl),\n    disp = round(disp),\n    hp = round(hp),\n    drat = round(drat),\n    wt = round(wt),\n    qsec = round(qsec),\n    vs = round(vs),\n    am = round(am),\n    gear = round(gear),\n    carb = round(carb)\n  )\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1    21     6   160   110     4     3    16     0     1     4     4\n 2    21     6   160   110     4     3    17     0     1     4     4\n 3    23     4   108    93     4     2    19     1     1     4     1\n 4    21     6   258   110     3     3    19     1     0     3     1\n 5    19     8   360   175     3     3    17     0     0     3     2\n 6    18     6   225   105     3     3    20     1     0     3     1\n 7    14     8   360   245     3     4    16     0     0     3     4\n 8    24     4   147    62     4     3    20     1     0     4     2\n 9    23     4   141    95     4     3    23     1     0     4     2\n10    19     6   168   123     4     3    18     1     0     4     4\n# ℹ 22 more rows\n\n\nOr we can let across() do the work for us. All we have to do is pass the function we want applied to all columns of our data frame:\n\nmtcars %&gt;%\n  mutate(across(.cols = everything(), .fns = round))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1    21     6   160   110     4     3    16     0     1     4     4\n 2    21     6   160   110     4     3    17     0     1     4     4\n 3    23     4   108    93     4     2    19     1     1     4     1\n 4    21     6   258   110     3     3    19     1     0     3     1\n 5    19     8   360   175     3     3    17     0     0     3     2\n 6    18     6   225   105     3     3    20     1     0     3     1\n 7    14     8   360   245     3     4    16     0     0     3     4\n 8    24     4   147    62     4     3    20     1     0     4     2\n 9    23     4   141    95     4     3    23     1     0     4     2\n10    19     6   168   123     4     3    18     1     0     4     4\n# ℹ 22 more rows\n\n\nTo supply your own expression, we can write our own function and pass it through to across():\n\ndivide_by_ten &lt;- function(x) {\n  new_x &lt;- x / 10\n\n  return(new_x)\n}\n\nmtcars %&gt;%\n  mutate(across(.cols = everything(), .fns = divide_by_ten))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2.1    0.6  16    11   0.39  0.262  1.65   0     0.1   0.4   0.4\n 2  2.1    0.6  16    11   0.39  0.288  1.70   0     0.1   0.4   0.4\n 3  2.28   0.4  10.8   9.3 0.385 0.232  1.86   0.1   0.1   0.4   0.1\n 4  2.14   0.6  25.8  11   0.308 0.322  1.94   0.1   0     0.3   0.1\n 5  1.87   0.8  36    17.5 0.315 0.344  1.70   0     0     0.3   0.2\n 6  1.81   0.6  22.5  10.5 0.276 0.346  2.02   0.1   0     0.3   0.1\n 7  1.43   0.8  36    24.5 0.321 0.357  1.58   0     0     0.3   0.4\n 8  2.44   0.4  14.7   6.2 0.369 0.319  2      0.1   0     0.4   0.2\n 9  2.28   0.4  14.1   9.5 0.392 0.315  2.29   0.1   0     0.4   0.2\n10  1.92   0.6  16.8  12.3 0.392 0.344  1.83   0.1   0     0.4   0.4\n# ℹ 22 more rows\n\n\nOr we can write it inline using the following syntax where ~ lets dplyr know to expect an inline function, and . is used as a placeholder for the variable.\n\nmtcars %&gt;%\n  mutate(across(.cols = everything(), .fns = ~ . / 10))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2.1    0.6  16    11   0.39  0.262  1.65   0     0.1   0.4   0.4\n 2  2.1    0.6  16    11   0.39  0.288  1.70   0     0.1   0.4   0.4\n 3  2.28   0.4  10.8   9.3 0.385 0.232  1.86   0.1   0.1   0.4   0.1\n 4  2.14   0.6  25.8  11   0.308 0.322  1.94   0.1   0     0.3   0.1\n 5  1.87   0.8  36    17.5 0.315 0.344  1.70   0     0     0.3   0.2\n 6  1.81   0.6  22.5  10.5 0.276 0.346  2.02   0.1   0     0.3   0.1\n 7  1.43   0.8  36    24.5 0.321 0.357  1.58   0     0     0.3   0.4\n 8  2.44   0.4  14.7   6.2 0.369 0.319  2      0.1   0     0.4   0.2\n 9  2.28   0.4  14.1   9.5 0.392 0.315  2.29   0.1   0     0.4   0.2\n10  1.92   0.6  16.8  12.3 0.392 0.344  1.83   0.1   0     0.4   0.4\n# ℹ 22 more rows\n\n\n\n\n5.4.2 summarize()\nSay we wanted to find the mean of every variable in the mtcars data. In this case we can still use across()!\n\nmtcars %&gt;%\n  summarize(across(.cols = everything(), .fns = mean))\n\n# A tibble: 1 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  20.1  6.19  231.  147.  3.60  3.22  17.8 0.438 0.406  3.69  2.81\n\n\nWe can calculate multiple summary statistics by passing in a list() of the statistics we want:\n\nmtcars %&gt;%\n  summarize(\n    n = n(),\n    across(\n      .cols = everything(),\n      .fns = list(mean = mean, median = median)\n    )\n  )\n\n# A tibble: 1 × 25\n      n mpg_mean mpg_median cyl_mean cyl_median disp_mean disp_median hp_mean\n  &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1    32     20.1       19.2     6.19          6      231.        196.    147.\n# ℹ 17 more variables: hp_median &lt;dbl&gt;, drat_mean &lt;dbl&gt;, drat_median &lt;dbl&gt;,\n#   wt_mean &lt;dbl&gt;, wt_median &lt;dbl&gt;, qsec_mean &lt;dbl&gt;, qsec_median &lt;dbl&gt;,\n#   vs_mean &lt;dbl&gt;, vs_median &lt;dbl&gt;, am_mean &lt;dbl&gt;, am_median &lt;dbl&gt;,\n#   gear_mean &lt;dbl&gt;, gear_median &lt;dbl&gt;, carb_mean &lt;dbl&gt;, carb_median &lt;dbl&gt;,\n#   n_mean &lt;dbl&gt;, n_median &lt;int&gt;\n\n\n\n\n5.4.3 Exercise 1\nStep 1: Open up a script, save it with a meaningful name, and load the tidyverse.\nStep 2: Use the mutate() and across() to take the log of each variable in mtcars.\nStep 3: Use the summarise() and across() to find the standard deviation (sd) of each variable in mtcars."
  },
  {
    "objectID": "05_lesson.html#where",
    "href": "05_lesson.html#where",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.5 where()",
    "text": "5.5 where()\n\n5.5.1 Example\nTo demonstrate where() we’ll use the diamonds data frame from ggplot2:\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\nWhat happens if we try to use mutate(acoss(.cols = everything(), .fns = log)) to log transform each variable in this data frame?\n\ndiamonds %&gt;%\n  mutate(across(.cols = everything(), .fns = log))\n\nError in `mutate()`:\nℹ In argument: `across(.cols = everything(), .fns = log)`.\nCaused by error in `across()`:\n! Can't compute column `cut`.\nCaused by error in `Math.factor()`:\n! 'log' not meaningful for factors\n\n\nIt doesn’t work because diamonds has some non-numeric columns. We could find all the columns that are numeric:\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\nAnd then write a lot of repetitive mutate() statements again. Instead let’s use where() as follows:\n\ndiamonds %&gt;%\n  mutate(across(.cols = where(is.numeric), .fns = log))\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 -1.47 Ideal     E     SI2      4.12  4.01  5.79  1.37  1.38 0.888\n 2 -1.56 Premium   E     SI1      4.09  4.11  5.79  1.36  1.35 0.837\n 3 -1.47 Good      E     VS1      4.04  4.17  5.79  1.40  1.40 0.837\n 4 -1.24 Premium   I     VS2      4.13  4.06  5.81  1.44  1.44 0.967\n 5 -1.17 Good      J     SI2      4.15  4.06  5.81  1.47  1.47 1.01 \n 6 -1.43 Very Good J     VVS2     4.14  4.04  5.82  1.37  1.38 0.908\n 7 -1.43 Very Good I     VVS1     4.13  4.04  5.82  1.37  1.38 0.904\n 8 -1.35 Very Good H     SI1      4.13  4.01  5.82  1.40  1.41 0.928\n 9 -1.51 Fair      E     VS2      4.18  4.11  5.82  1.35  1.33 0.912\n10 -1.47 Very Good H     VS1      4.08  4.11  5.82  1.39  1.40 0.871\n# ℹ 53,930 more rows\n\n\nWhen using the where() with across(), we first supply the condition that must be met, and then the function to apply to the columns that meet that condition. So in the above example, we first test if a column is.numeric, and then apply log to those that are.\nWe can use select() and where() to subset only those columns that are numeric:\n\ndiamonds %&gt;%\n  select(where(is.numeric))\n\n# A tibble: 53,940 × 7\n   carat depth table price     x     y     z\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23  61.5    55   326  3.95  3.98  2.43\n 2  0.21  59.8    61   326  3.89  3.84  2.31\n 3  0.23  56.9    65   327  4.05  4.07  2.31\n 4  0.29  62.4    58   334  4.2   4.23  2.63\n 5  0.31  63.3    58   335  4.34  4.35  2.75\n 6  0.24  62.8    57   336  3.94  3.96  2.48\n 7  0.24  62.3    57   336  3.95  3.98  2.47\n 8  0.26  61.9    55   337  4.07  4.11  2.53\n 9  0.22  65.1    61   337  3.87  3.78  2.49\n10  0.23  59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n5.5.2 Exercise 2\nNote: Each step is a separate task. They need not be piped together.\nStep 1: Use select() and where() to subset all the columns from diamonds that are factor variables.\nStep 2: Use the mutate(), across(), and where() to take the sqrt of each numeric variable in diamonds.\nStep 3: Use the summarise, across(), and where() to find the mean and standard deviation of each numeric variable in diamonds.\nStep 4: Use summarise() and across() to find the mean and standard deviation of each numeric variable in diamonds, first using group_by(), across(), and where() to group by all factor variables."
  },
  {
    "objectID": "05_lesson.html#selector-helpers",
    "href": "05_lesson.html#selector-helpers",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.6 Selector Helpers",
    "text": "5.6 Selector Helpers\nSometimes we want to use across() with many variables but not all variables or not all variables of a certain type. We can use a character vector to pick a subset of columns.\n\ndiamonds %&gt;%\n  mutate(across(.cols = c(\"x\", \"y\", \"z\"), .fns = log))\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  1.37  1.38 0.888\n 2  0.21 Premium   E     SI1      59.8    61   326  1.36  1.35 0.837\n 3  0.23 Good      E     VS1      56.9    65   327  1.40  1.40 0.837\n 4  0.29 Premium   I     VS2      62.4    58   334  1.44  1.44 0.967\n 5  0.31 Good      J     SI2      63.3    58   335  1.47  1.47 1.01 \n 6  0.24 Very Good J     VVS2     62.8    57   336  1.37  1.38 0.908\n 7  0.24 Very Good I     VVS1     62.3    57   336  1.37  1.38 0.904\n 8  0.26 Very Good H     SI1      61.9    55   337  1.40  1.41 0.928\n 9  0.22 Fair      E     VS2      65.1    61   337  1.35  1.33 0.912\n10  0.23 Very Good H     VS1      59.4    61   338  1.39  1.40 0.871\n# ℹ 53,930 more rows\n\n\nSometimes this is cumbersome. Fortunately, library(dplyr) has helpers that can create character vectors for use. For instance, if all of the variables we care about start with “e”, then we can\n\ndata %&gt;%\n  mutate(across(.cols = starts_with(\"e\"), .fns = log))\n\n\nThere are several selector helpers:\n\ncontains()\nends_with()\nmatches()\nnum_range()\none_of()\nstarts_with()"
  },
  {
    "objectID": "05_lesson.html#pivot_",
    "href": "05_lesson.html#pivot_",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.7 pivot_*",
    "text": "5.7 pivot_*\nWarning: across() is not an excuse to avoid tidy data! For example, the following is bad. Why does this violate tidy data? How much pain would we experience if we wanted to plot this data?\n\ndata &lt;- tribble(\n  ~state, ~`1999`, ~`2000`, ~`2001`,\n  \"Maryland\", 100, 110, 121,\n  \"Virginia\", 205, 204, 203\n)\n\nWe use pivot_longer() to transform data from wide to long and pivot_wider() to transform data from long to wide.\nWe can fix the above data with pivot_longer()\n\ndata_long &lt;- data %&gt;%\n  pivot_longer(\n    cols = -state,\n    names_to = \"year\",\n    values_to = \"widget_factories\"\n  )\n\ndata_long\n\n# A tibble: 6 × 3\n  state    year  widget_factories\n  &lt;chr&gt;    &lt;chr&gt;            &lt;dbl&gt;\n1 Maryland 1999               100\n2 Maryland 2000               110\n3 Maryland 2001               121\n4 Virginia 1999               205\n5 Virginia 2000               204\n6 Virginia 2001               203\n\n\nWe can unfix the data with pivot_wider()\n\ndata_long %&gt;%\n  pivot_wider(\n    id_cols = state,\n    names_from = year,\n    values_from = widget_factories\n  )\n\n# A tibble: 2 × 4\n  state    `1999` `2000` `2001`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Maryland    100    110    121\n2 Virginia    205    204    203\n\n\n\n5.7.1 Tidy data\n\nHappy families are all alike; every unhappy family is unhappy in its own way. ~ Leo Tolstoy\n\n\ntidy datasets are all alike but every messy dataset is messy in its own way ~ Hadley Wickham\n\nTools optimized for one data format are going to be more powerful than tools optimized for any data format. If we can standardize our data, then we will have really powerful tools.\nUnfortunately, most people do not pay enough attention to the structure, storage, and dissemination of data."
  },
  {
    "objectID": "05_lesson.html#librarypurrr",
    "href": "05_lesson.html#librarypurrr",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.8 library(purrr)",
    "text": "5.8 library(purrr)\nSometimes, we’re going to want to iterate on a data structure other than a tibble or iterate a function that isn’t vectorized.\n\n5.8.1 Many files\nOne approach is to use for loops. For loops are useful and should be understood. This code writes nine .csv files with 1000 random draws from a standard normal distribution.\n\ndir.create(\"data\")\n\nfor (i in 1:9) {\n  tibble(\n    id = 1:1000,\n    value = rnorm(1000)\n  ) %&gt;%\n    write_csv(path = paste0(\"data/data\", i, \".csv\"))\n}\n\nlibrary(purrr) is a powerful alternative to for loops that is designed for functional programming. This code reads in the nine .csv files!\n\nfiles &lt;- list.files(path = \"data\", full.names = TRUE)\n\nmap(.x = files, .f = read_csv)\n\nmap() always returns a list! map_*() functions can be used to return different data structures. For instance, map_chr() will always return a character vector. map_df() is like the code above but returns one data frame instead of a list of smaller data frames.\n\nmap_df(.x = files, .f = read_csv)\n\n\n\n5.8.2 Many models\n\nlibrary(broom)\n\n# estimate a linear model for each of seven colors\nmany_models &lt;- diamonds %&gt;%\n  split(diamonds$color) %&gt;%\n  map(~ lm(formula = price ~ carat + cut, data = .))\n\n# extract model diagnostics from each model\nmany_models_results &lt;- bind_cols(\n  color = names(many_models),\n  map_df(many_models, glance)\n)\n\n# plot\nmany_models_results %&gt;%\n  ggplot(aes(color, r.squared)) +\n  geom_col() +\n  scale_y_continuous(\n    expand = c(0, 0),\n    limits = c(0, 1)\n  ) +\n  labs(title = \"R-Squared for linear models estimated on subsets by color\") +\n  theme_minimal()\n\n\n\n\nThese examples are beyond the scope of an introductory class but I wanted to demonstrate the power of iteration in R. These tools can be used iterate data visualizations, R Markdown reports, statistical models, computer operations like file creation and transfer, and more."
  },
  {
    "objectID": "05_lesson.html#resources",
    "href": "05_lesson.html#resources",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "5.9 Resources",
    "text": "5.9 Resources\n\ndplyr 1.0.0: working across columns\nPivoting in R4DS"
  },
  {
    "objectID": "06_lesson.html#key-takeaways",
    "href": "06_lesson.html#key-takeaways",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "6.1 Key Takeaways",
    "text": "6.1 Key Takeaways\n\nTake notes/annotate code as you go\nUse the assignment operator\nRead your error messages\nData import with read_csv()\nData management with library(dplyr)\nVisualization with library(ggplot2)"
  },
  {
    "objectID": "06_lesson.html#helpful-packages",
    "href": "06_lesson.html#helpful-packages",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "6.2 Helpful Packages",
    "text": "6.2 Helpful Packages\n\nImport Data\n\nreadr - for plain text files\nreadxl - for Excel files\nhaven - for SAS, SPSS, and Stata data formats\nhere - set directory\nremotes or devtools - install packages from Github\narrow - read/save binary data\n\nManipulate data\n\ntidyverse - format tidy data (includes the following packages)\ndplyr - wrangle data using %&gt;%\nlubridate - clean dates\nstringr - clean strings\npurrr - iterate\n\nVisualize data\n\nggplot2 - plots!\nurbnthemes - format and style according to Urban Style\nurbnmapr - create Urban themed maps"
  },
  {
    "objectID": "06_lesson.html#what-is-r-markdown",
    "href": "06_lesson.html#what-is-r-markdown",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "6.3 What is R Markdown?",
    "text": "6.3 What is R Markdown?\n\n\n\n\n\nSource: RStudio\n\nThis webpage is a Markdown! It creates a pdf/word/html output file that can include:\n\nCode chunks\nCode output (graphs/charts/tables)\nFormatted text and images"
  },
  {
    "objectID": "06_lesson.html#urbntemplates",
    "href": "06_lesson.html#urbntemplates",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "6.4 urbntemplates",
    "text": "6.4 urbntemplates\nlibrary(urbntemplates) contains three families of functions:\n\nstart_project() generates a new project with a .Rproj, README, and .gitignore at the specified location on a machine.\nconstruct_*() functions add multiple, related templates and documents to a project directory or sub-directory. The templates and documents are related in important ways. For example, construct_shiny() adds app.R and an R Shiny specific CSS. It also adds instructions for using the selected template.\nuse_*() functions add individual templates and documents to a project directory or sub directory.\n\nA sensible workflow is: 1. Start a new project and create a .Rproj by submitting urbntemplates::start_project(). This will create and open a new .Rproj. 2. Inside the .Rproj, add the necessary documents for a part of a project, like a Shiny application, with a construct_() function. 3. Add any desired remaining templates or documents with use_() functions.\n\n6.4.0.1 start function\n\nstart_project()\n\n\n\n6.4.0.2 construct functions\n\nconstruct_shiny()\nconstruct_fact_sheet_html()\nconstruct_fact_sheet_pdf()\nconstruct_slide_show()\nconstruct_web_report()\n\n\n\n6.4.0.3 use functions\n\nuse_content()\nuse_css()\nuse_fact_sheet_html()\nuse_fact_sheet_pdf()\nuse_git_ignore_urbn()\nuse_instructions()\nuse_iterate()\nuse_preamble()\nuse_revealjs()\nuse_shiny_app()\nuse_readme_readme()\nuse_web_report()\n\n\n\n6.4.1 YAML Header\nControls the settings of the document.\n\n\n6.4.2 Markdown\nMarkdown is a lightweight markup language for creating formatted text using a plain-text editor. R Markdown Reference Guide\n\n\n6.4.3 Code Chunks\nCreates the code output for the document.\n\n\n6.4.4 Create a Markdown HTML Fact Sheet - Piece by Piece\n\n\n6.4.5 Step 1: Install library(urbntemplates)\ninstall.packages(\"remotes\")\nremotes::install_github(\"UrbanInstitute/urbntemplates\")\nStep 2: Create a new project using start_project()(Parenthesis should have directory and name of new project). Once you create the project, open a new script and create an html fact sheet using urbntemplates::construct_fact_sheet_html()\nStep 3: Resave the .Rmd with a better name.\nStep 4: Knit the R Markdown into a pdf document.\nStep 5: Add some text into the markdown, some code that appears as code, and some code that shows the result but not the code. Every code chunk should start with {r name} and then set the parameters (T/F, separated by comma. See full factsheet for more parameters."
  },
  {
    "objectID": "06_lesson.html#resources",
    "href": "06_lesson.html#resources",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "6.5 Resources",
    "text": "6.5 Resources\n\nRStudio R Markdown guide\nR Markdown: The Definitive Guide\nR4DS"
  }
]