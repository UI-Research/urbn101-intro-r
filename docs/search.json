[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to R",
    "section": "",
    "text": "Intro to R: A Hands on Tutorial\nThis book contains the materials for Intro to R: A hands-on tutorial, a multi-class R training hosted by the Urban Institute R Users Group.\nCore lessons include:"
  },
  {
    "objectID": "index.html#instructors-across-all-years",
    "href": "index.html#instructors-across-all-years",
    "title": "Intro to R",
    "section": "Instructors (across all years)",
    "text": "Instructors (across all years)\n\nAaron R. Williams (IBP/TECH)\nAmy Rogin (MET)\nAjjit Narayanan (TECH)\nFay Walker (MET)\nSarah Strochak (HFPC)\nKyle Ueyama (TECH)\nOlivia Fiol (MET)\n\n\nQuestions?\nContact Amy Rogin (arogin@urban.org) or Aaron Williams (awilliams@urban.org)"
  },
  {
    "objectID": "02_lesson.html",
    "href": "02_lesson.html",
    "title": "2  Data Munging 1",
    "section": "",
    "text": "3 Review\n\nAssignment Operator\nConsole/Environment/Script\nComment your code and read your error messages\n\n\n\n4 The tidyverse package\n\nCollection of packages using same syntax and grammar\nWorks with “tidy” data\nUses tibbles (https://r4ds.had.co.nz/tibbles.html)\n%>%\n\n\n\n5 Primary functions\n\nselect()\nrename()\nfilter()\narrange()\nmutate()\ngroup_by()\nsummarize()\n\nAll of these functions have the same structure.\n\nThe first argument is the dataframe\nThe subsequent arguments describe what to do with the data frame, using the variable names (without quotes because you’re already refering to that df)\nSeparate functions by %>%\nThe result is a new data frame.\n\n\n\nIf you have hit an error, trying running it line by line (function by function)\n\nSource: R for data science\n\n\n6 Exercise 0: Creating a Project and Loading Packages\nIf you are using a different computer or didn’t attend sessions 0 or 1, follow steps 1 and 2. If not- skip to step 3.\nStep 1: Open RStudio. File > New Project > New Directory > Select the location where you would like to create a new folder that houses your R Project. Call it urbn101.\nStep 2: Open an .R script with the button in the top left (sheet with a plus sign icon). Save the script as 02_data-munging1.R.\nStep 3: If you have not previously installed library(tidyverse): submit install.packages(\"tidyverse\") to the Console (type and hit enter)\nStep 4: Write library(tidyverse) at the top of 02_data-munging1.R. With the cursor on the line of text, click Control-Enter.\n\n\n7 Exercise 1: Tidyverse Function Overview\nStep 1: Assign the storms dataset to be called storms. Submit View(storms) in the console.\nYou can also deselect specific columns in your data by using the - operator\nSelect\nselect() is used when you want to limit the number of columns in your dataframe. The arguments after the dataframe should be names of columns, without quotes. For example:\ndataset %>%\n  select(col1, col2)\nStep 2: Create a new dataset with all the variables except for ts_diameter and hu_diameter, by using select and -.\nStep 3: Create a new dataset that only category 5 storms using filter().\nFilter\nfilter() is used when you want to filter to specific rows in your dataframe, based on certain conditions. Filter works with the following comparison operators:\n\n<, >, <=, >=\n==, !=\n\nYou can also chain together multiple condtions with & (and) or | (or). The arguments after the dataframe should be conditions you want to filter your dataset on. For example\ndataset %>%\nfilter(col1>0)\nStep 4: Chain all of these commands together with the %>% operator. Then rename the column pressure to air_pressure.\nRename\nThe syntax for rename is:\ndataset %>% \n  rename(new_name = current_name)\nThis same syntax can be used inside select(), and you can rename and select variables simultanously.\nStep 5: wind is measured in knots. Convert wind into miles per hour. Each knot is equal to 1.15078 miles per hour.\nMutate\nmutate() can make new variables and edit existing variables. New variables are always added to the end of the dataframe. You can use arithmetic arguments, such as +, -, *, /, and ^. The syntax for mutate is:\ndataset %>% \n  mutate(new_column = 100 * other_column)\nStep 6: Make a dataset with storms that occured in the summer (June, July, August).\nThe %in% operator\nThe %in% operator is useful for filtering based on more than one option within one variable.\nfilter(dataset, var1 == \"a\" | var1 == \"b\" | var1 == \"c\")\nis equivalent to\ndataset %>%\nfilter(var1 %in% c(\"a\", \"b\", \"c\"))\n\n\n8 Exercise 2: If/Then and Summarizing\nStep 1: Use the txhousing dataset. Assign the dataset to an object in your global environment named tx_housing.\nStep 2: Compute a new variable, average_price by dividing volume by sales.\nStep 3: Use if_else() to create a variable called flag that is 1 if the average sales price is larger than the median sales price.\nIf/then logic\nif_else() is an important tool in combination with mutate(). It employs if-then logic: the first argument is a binary statement. The second statement says what to do if the first argument is evaluated to TRUE- the third is what to do if it is FALSE This is particularly useful for creating dummy or indicator variables. When you have more than two possible outcomes, it is more efficient to use case_when().\nStep 3a: Type ?case_when into the console.\nStep 4: Type the following code into your script.\ntx_housing %>% \n  group_by(year) %>% \n  summarize(yearly_sales = sum(sales))\nGroup By\ngroup_by groups your dataframe into discrete categories. It can be very powerful when used with summarize.\nSummarize\nsummarize computes summary statistics for as set of observations in your data. The syntax is:\ndataset %>% \n  mutate(max = max(other_column))\nor\ndataset %>%\n  group_by(col1) %>%\n  summarize(count=n())\nStep 5: Add the argument na.rm = TRUE to the sum() function and rerun the code. Add a comment to explain the code.\nStep 6: Sort the results of the previous code in order from most to least sales by adding %>% arrange(desc(yearly_sales)) to the end of the code.\nStep 7a: Which city had the most home sales in January 2008? (Hint: use filter() and arrange()).\nStep 7b: Which city had the least home sales in 2006? (Hint: group by the city and the year- then use summarize()).\nBONUS: Plot the number of annual home sales over time!\n\n\n9 Exercise 3: Put it all together\nStep 1: Use the starwars dataframe. Type count(starwars, homeworld) into your script.\nStep 2: Filter out any characters that have a missing homeworld.\nStep 3: Find the average and median height and mass for humans vs. droids. (Hint: use group_by() and summarize()). Make sure that you are correcting for observations with missing values!\nStep 4: Make a dummy variable called droid that is 1 for droids and 0 for humans. Make a variable called tall that is 1 if the characters are more than 200 cm tall. How many tall humans are there?\nStep 5: What is the most common skin color for droids?\n\n\n10 Resources\n\nR for Data Science: data transformation\nData wrangling cheat sheet"
  },
  {
    "objectID": "06_lesson.html",
    "href": "06_lesson.html",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "",
    "text": "7 Key Takeaways\nSource: RStudio\nlibrary(urbntemplates) contains three families of functions:\nA sensible workflow is: 1. Start a new project and create a .Rproj by submitting urbntemplates::start_project(). This will create and open a new .Rproj. 2. Inside the .Rproj, add the necessary documents for a part of a project, like a Shiny application, with a construct_() function. 3. Add any desired remaining templates or documents with use_() functions.\nStep 1: Install library(urbntemplates)\nStep 2: Create a new project using start_project()(Parenthesis should have directory and name of new project). Once you create the project, open a new script and create an html fact sheet using urbntemplates::construct_fact_sheet_html()\nStep 3: Resave the .Rmd with a better name.\nStep 4: Knit the R Markdown into a pdf document.\nStep 5: Add some text into the markdown, some code that appears as code, and some code that shows the result but not the code. Every code chunk should start with {r name} and then set the parameters (T/F, separated by comma. See full factsheet for more parameters."
  },
  {
    "objectID": "06_lesson.html#yaml-header",
    "href": "06_lesson.html#yaml-header",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "10.1 1. YAML Header",
    "text": "10.1 1. YAML Header\nControls the settings of the document."
  },
  {
    "objectID": "06_lesson.html#markdown",
    "href": "06_lesson.html#markdown",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "10.2 2. Markdown",
    "text": "10.2 2. Markdown\nMarkdown is a lightweight markup language for creating formatted text using a plain-text editor. R Markdown Reference Guide"
  },
  {
    "objectID": "06_lesson.html#code-chunks",
    "href": "06_lesson.html#code-chunks",
    "title": "6  Putting it All Together (and into Markdown)",
    "section": "10.3 3. Code Chunks",
    "text": "10.3 3. Code Chunks\nCreates the code output for the document."
  },
  {
    "objectID": "01_lesson.html",
    "href": "01_lesson.html",
    "title": "1  Data Visualization",
    "section": "",
    "text": "2 Review\nWhy Use R instead of Excel?\n\nReproducibility\nScalability\nFlexibility\nIterative\nOpen Source\n\nRemember\n\nEnvironment/scripts/console\nComment your code as you go\nRead your error messages\nWhere possible, type, don’t copy and paste - you will remember better!\nThe assignment operator\n\n\n\n3 Exercise 0 (Set up a project and load packages)\nStep 1: Open RStudio. File > New Project > New Directory > Select the location where you would like to create a new folder that houses your R Project. Call it urbn101\nStep 2: Open an .R script with the button in the top left (sheet with a plus sign icon). Save the script as 01_data-visualization.R.\nStep 3: Type install.packages(\"tidyverse\") and hit enter (submit) to the Console.\nStep 4: Write library(tidyverse) and at the top of 01_data-visualization.R. With the cursor on the line of text, hit Control-Enter (at the same time).\nStep 5: Repeat steps 3 & 4 with install.packages(\"ggplot2\") and library(ggplot2), respectively.\n\ntidyverse - a collection of libraries that use the same syntax/grammar (more on this on Monday)\nggplot2 - for making plots/graphs\n\n\n\n4 Exercise 1 (Make a plot)\nStep 1: Submit data() to the console. We will use the airquality dataset.\nStep 2: Type the following in your script:\nggplot(data=airquality)+\n  geom_point(mapping=aes(x=Temp, y=Ozone))\n\nData frames are the only appropriate input for library(ggplot2).\n\nStep 3: Add a comment above the ggplot2 code that describes the plot we created.\nStep 4: Add comments below the data visualization code that describes the argument or function that corresponds to each of the first three components of the grammar of graphics.\nData are the values represented in the visualization.\nAesthetic mappings are directions for how data are mapped in a plot in a way that we can perceive. Aesthetic mappings include linking variables to the x-position, y-position, color, fill, shape, transparency, and size.\nGeometric objects are representations of the data, including points, lines, and polygons.\n\n\n5 Exercise 2 (Change some of the plot settings)\nStep 1: Duplicate the code from your first chart. Inside aes(), add color = \"red\" (separated by a comma)\nStep 2: Move color = \"red\" from aes() to geom_point(). What changed?\nStep 3: Remove color = \"red\" and add color = Month inside aes().\nStep 4: This is a little cluttered. Add alpha = 0.2 inside geom_point().\nStep 5: Add a plus sign to the end of the geom_point line, type labs(title=\"Air Quality Temperature and Ozone Readings\")\nAesthetic mappings like x and y almost always vary with the data. Aesthetic mappings like color, fill, shape, transparency, and size can vary with the data. But those arguments can also be added as styles that don’t vary with the data. If you include those arguments in aes(), they will show up in the legend (which can be annoying!).\n\n\n6 Exercise 3 (Add a regression line/confidence interval)\nStep 1: Reconfigure the data so that the geompoint parentheses are empty (move mapping=aes(x=Temp, y=Ozone) to the ggplot line. Add + to the labs line and add geom_smooth()\n\n\n7 Exercise 4 (Scale the axes)\nStep 1: Create a new scatter plot using the msleep data set. Use bodywt on the x-axis and sleep_total on the y-axis.\nStep 2: The y-axis doesn’t contain zero. Below geom_point(), add scale_y_continuous(lim = c(0, NA)). Hint: add + after geom_point().\nStep 3: The x-axis is clustered near zero. Add scale_x_log10() above scale_y_continuous(lim = c(0, NA)).\nScales Turn data values, which are quantitative or categorical, into aesthetic values. This includes not only the x-axis and y-axis, but the ranges of sizes, shapes, and colors of aesthetics.\n\n\n8 Exercise 5 (Make it look nice!!)\nStep 1: Add the following code to your script. Submit it!\nggplot(storms)+ \ngeom_bar(mapping=aes(category))\nStep 2: Run install.packages(\"remotes\") and remotes::install_github(\"UrbanInstitute/urbnthemes\") in the console.\nStep 3: In the lines preceding the chart add and run the following code:\nlibrary(urbnthemes)\nset_urbn_defaults(style = \"print\")\nStep 4: Run the code to make the chart.\nStep 5: Add scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) and rerun the code.\nTheme controls the visual style of plot with font types, font sizes, background colors, margins, and positioning.\n\n\n9 Excercise 6 (Multiple little graphs/Faceting)\nStep 1: Read in Zillow Observed Rent Index (ZORI) data using read_csv('https://raw.githubusercontent.com/UI-Research/urbn101-intro-r/master/homework/zillow_clean.csv')\nStep 2: Clean the zillow data to just the most expensive ciites using code below:\nzillow_clean <- zillow %>%\n  arrange(desc(Avg_price)) %>%\n  slice(1:10) %>%\n  ggplot()+\n  geom_point(mapping=aes(x=Year, y=Avg_price))\nStep 3: In ggplot, plot the zillow_clean data as a scatter plot with year on the x axis and avg_price on the y axis.\nStep 4: Add facet_wrap(~RegionName) after the geom_point(mapping=aes(x=Year, y=Avg_price)) line.\n\n\n10 Exercise 7 (Mapping)\nStep 1: Read in UFO sighting data (source: National UFO Reporting Center), link: https://raw.githubusercontent.com/UI-Research/urbn101-intro-r/master/homework/ufo_state.csv\nStep 1: Install urbnmapr devtools::install_github(\"UrbanInstitute/urbnmapr\"), load the urbnmapr library, and update the urbnthemes style to map set_urbn_defaults(style = \"map\").\nStep 2:: Pull a shapefile of US States using urbnmapr and join the UFO counts by state to the shapefile using the code below:\nstates_sf <- get_urbn_map(\"states\", sf = TRUE)\n\nstates_ufo <- states_sf %>% \n  left_join(ufo, by=c(\"state_abbv\"=\"state\"))\nStep 3:: In ggplot, plot the states_ufo dataset, fill it in using the “count” column, add labels, change the outline (colour). Instead of using geom_point or geom_bar using geom_sf.\n Mapping Resources \n\nHow to Create State and County Maps Easily in R\nlibrary(urbnmapr)\nUrban Institute R Users Group website: mapping\n\n\n\n11 Functions\n\nggplot(): Create a plot, pull in data\naes(): The aesthetics that show up in the legend\ngeom_*(): What kind of graph\n\ngeom_point()\ngeom_line()\ngeom_bar()\ngeom_col()\ngeom_sf()\n\nscale_*(): The units on the x/y axis (discrete/continuous)\n\nscale_y_continuous()\n\nlabs(): Labels\n\nx/y/title/fill/colour\n\n\n\n\n12 Theory\n\nData\nAesthetic mappings\nGeometric objects\nScales\nCoordinate systems\nFacets\nStatistical transformations\nTheme\n\n\n\n13 Resources\n\nUrban Institute R Users Group website\nWhy the Urban Institute visualizes data with ggplot2\nR for Data Science: data visualization\nawunderground themes\nR Graph Gallery\n“A Layered Grammar of Graphics” by Hadley Wickham"
  },
  {
    "objectID": "03_lesson.html",
    "href": "03_lesson.html",
    "title": "3  Data Munging (II)",
    "section": "",
    "text": "4 Review\nLast week, we showed how mutate() can be used to create new variables or to transform new variables. For example, we converted knots into miles per hour. We also learned about if_else last week which works great for one condition. But what if you have multiple conditions? case_when() allows for a sequence of conditional logic that can be used to transform or create variables with mutate(). For example, here I create a variable called lateness that creates a character variable with the levels \"very late\", \"late\", and \"on time\". The logic is evaluated from top to bottom and TRUE is used to refer to all other remaining cases.\nThe syntax may look a little weird at first but it’s easy to pick up! The logical condition goes to the left of ~ and the output results goes to the right. & and | can be used to combine logical statements.\nlibrary(stringr) contains powerful and concise functions manipulating character variables. Reference the cheat sheet for an overview of the different string maniuplation functions.\nlibrary(lubridate) contains powerful and concise functions for creating and manipulating dates, times, and date-times. It is aware of leap days and leap seconds and is useful for calculating periods, durations, intervals, and more.\nThis is often the hardest concept to fully grasp, but it’s also the most powerful!\nJoins are the main method for combining two datasets with a commmon key column together. There are many types of joins, and we highly recommend you read this chapter on joins in R4DS if you want more info. Below is a quick visual summary of the types of joins you can perform in R.\nFor now we will focus on the “left” join, which merges observations from the right data set to the left data set. This is the join type I use 90% of the time in R. Below is an example of how the left_join() function works.\nSometimes functions don’t exist for desired calculations or we want to combine many calculations into one function to reduce copying-and-pasting.\n“You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).” ~ R4DS\nR has a flexible function system that makes it very easy to define custom functions!\nThree ingredients\nNote: Using tidyverse functions inside of custom functions often requires non-standard evaluation. Please reach out for help when this is your goal.\nR contains a full set of functions for managing files and folders on your computer\nWhat do you think this below chunk of code is doing in plain English?\nConditional logic is an important concept in computer programming. We already used ifelse() and case_when() to create indicator variables and conditional variables. Sometimes it’s also useful to run entire chunks of code conditionally.\nThree ingredients"
  },
  {
    "objectID": "03_lesson.html#exercise-1",
    "href": "03_lesson.html#exercise-1",
    "title": "3  Data Munging (II)",
    "section": "7.1 Exercise 1",
    "text": "7.1 Exercise 1\nThe month and day columns are currently integer variables. We want to turn them into character variables with leading zeros. For example, 1 should be \"01\".\nStep 1: Use mutate() to overwrite month and day with str_pad(). The first argument should be month or day. The second argument, width, should be 2.\nStep 2: The padding character is currently a space, but we want it to be \"0\". Use ?str_pad to figure out how to switch the padding character.\nStep 3: Pipe the result into the following line mutate(flight_date = paste(year, month, day, sep = \"-\"))\nStep 4: Drop all variables except flight_date, distance, and air_time.\nStep 5: Assign the result to flights_subset."
  },
  {
    "objectID": "03_lesson.html#exercise-2",
    "href": "03_lesson.html#exercise-2",
    "title": "3  Data Munging (II)",
    "section": "8.1 Exercise 2",
    "text": "8.1 Exercise 2\nStep 1: Add library(lubridate) after library(nycflight13) in your script.\nStep 2: library(lubridate) is powerful but it needs variables in the correct format. Use ymd() inside of mutate() to turn the flight_date variable into a date rather than a character vector.\nStep 3: Inside the previous mutate statement, add another column called weekday for the weekday of the flight. You can use wday(flight_date) to find the day of the week for each date.\nStep 4: Assign the result to flights_subset.\nStep 5: Use count() to count the number of flights by day of the week."
  },
  {
    "objectID": "03_lesson.html#exercise-3",
    "href": "03_lesson.html#exercise-3",
    "title": "3  Data Munging (II)",
    "section": "9.1 Exercise 3",
    "text": "9.1 Exercise 3\nWe are going to summarize flights_subset from the previous example by week_day\nStep 1: group_by() week_day and use n() in summarize() to count the number of observations. This should match Step 5 from the previous exercise.\nStep 2: In the same summarize(), calculate mean(), and max() distance.\nStep 3: In the same summarize(), calculate median air_time.\nStep 4: Rename the resulting variables inside summarize() so they have more useful names."
  },
  {
    "objectID": "03_lesson.html#exercise-4",
    "href": "03_lesson.html#exercise-4",
    "title": "3  Data Munging (II)",
    "section": "10.1 Exercise 4",
    "text": "10.1 Exercise 4\nflights contains information about flights and the unit of observation is airplane flights. planes contains information about the airplanes and the unit of observation is the airplane. The common column between these tables is the tailnum column.\nWe want to add information about planes to the flights data set. This is a left join because for every flight in the dataset, we want to append flight information. This is also called a many-to-one join because we are joining many rows from the flights data to one row from the planes data.\nStep 1: Use left_join() to join planes to flights. The common key is tailnum.\nStep 2: Use anti_join() to see observations from flights that don’t have a match in planes and call the output object unmatched_flights. The common key is tailnum.\nStep 2: Use slice() to extract the tailnum value in the first row of unmatched_flights. Call this variable first_unmatched_tailnum\nStep 3: Use filter() to see if first_unmatched_tailnum is in planes. Hint: it shouldn’t be!"
  },
  {
    "objectID": "03_lesson.html#exercise-5",
    "href": "03_lesson.html#exercise-5",
    "title": "3  Data Munging (II)",
    "section": "11.1 Exercise 5",
    "text": "11.1 Exercise 5\nStep 1: Write a function called multiply_xy() that takes arguments x and y and multiplies them together.\nStep 2: Add your favorite number as the default for x and your least favorite number as the default for y.\nStep 3: Call the function and overwrite the default for y with your favorite number."
  },
  {
    "objectID": "03_lesson.html#exercise-6",
    "href": "03_lesson.html#exercise-6",
    "title": "3  Data Munging (II)",
    "section": "12.1 Exercise 6",
    "text": "12.1 Exercise 6\nStep 1: Check to see if you are in an R project. Use dir.create() to create a folder called final-data/.\nStep 1: Use file.copy() to duplicate your script and then delete the copy with file.remove(). CAREFUL! There is no undo button!"
  },
  {
    "objectID": "03_lesson.html#example",
    "href": "03_lesson.html#example",
    "title": "3  Data Munging (II)",
    "section": "13.1 Example",
    "text": "13.1 Example\n\nx <- 1000\n\nif (x > 999) {\n  print(\"x is big\")\n} else {\n  print(\"x is small\")\n}\n\n[1] \"x is big\""
  },
  {
    "objectID": "04_lesson.html",
    "href": "04_lesson.html",
    "title": "4  Data Import",
    "section": "",
    "text": "5 Review\nWe’ll be using three packages from the tidyverse for data import and export. These three should cover just about all of your use cases at Urban.\nOne note - while all three packages are installed with the tidyverse, only readr is loaded when you run library(tidyverse) in your R session. The other packages must be loaded separately.\nIn general, readr, readxl, and haven will come with some variant of a read function for data import, and a variant of write (except for Excel and SAS!) for data export.\nFor the simplest use cases, the various read functions will need just one argument: the path to the file you want to load.\nThe various write functions will need two arguments: the data frame you want to export, and the file path to save it to.\nreadr provides functions to read plain text rectangular data - think csv, txt or tsv files.\nFor data that is saved as .xls or .xlsx, use the readxl package.\nFinally, your SAS, SPSS, or Stata data can find safe haven in R.\nSometimes when you save text files, the column types (ie numeric, date, time, text, etc.) get lost and won’t be read back in upon reimporting In this case you may want to save your files as a binary file. One binary file format we suggest is .feather files, which you can read more about. The main benefits of storing data in a binary format is:\nThe cons are that:\nSo think before exercising this option! If you mainly will be working with your data in R and have large file sizes or complicated column types, .feather files may be a good option.\nYou can read and write these files with read_feather() and write_feather respectively."
  },
  {
    "objectID": "04_lesson.html#exercise",
    "href": "04_lesson.html#exercise",
    "title": "4  Data Import",
    "section": "9.1 Exercise",
    "text": "9.1 Exercise\nStep 1: Open up your RStudio project, open a R script, save it with a meaningful name, and load the tidyverse, readxl, haven, and arrow.\nStep 2: Use the dir.create() function to create subfolders called data and modified in your R Project.\nStep 3: We’ll be downloading a couple different datasets for today’s examples. Staying DRY, let’s rework the example code from Wednesday into a function we can reuse. Copy and paste the following into your file. Make sure to run the code so the function becomes a part of your environment.\n\ndownload_data <- function(url, path) {\n  if (!file.exists(path)) {\n    download.file(url, path, mode = \"wb\")\n  }\n}"
  },
  {
    "objectID": "04_lesson.html#csv-files",
    "href": "04_lesson.html#csv-files",
    "title": "4  Data Import",
    "section": "10.1 CSV Files",
    "text": "10.1 CSV Files\n\n10.1.1 Example\nFirst we’ll download an example csv file from the Urban Institute’s Education data portal:\n\n# Download ipeds data into data/ folder\ndownload_data(\"https://educationdata.urban.org/csv/ipeds/colleges_ipeds_completers.csv\",\n              \"data/colleges_ipeds_completers.csv\")\n\nAnd then use read_csv from the readr package to load the data in.\n\nipeds <- read_csv(\"data/colleges_ipeds_completers.csv\")\n\nWe now have a tibble that can be used with all the ggplot2 and dplyr functions you’ve learned so far. Let’s filter the data to only 2011 and write it out as a separate file:\n\nipeds_2011 <- ipeds %>%\n  filter(year == 2011)\n\nwrite_csv(ipeds_2011, \"modified/colleges_ipeds_completers_2011.csv\")\n\n\n\n10.1.2 Exercise\nStep 1: Filter the ipeds data frame to years 2014-2015 for the state of California (HINT: fips code of 6). Be sure to use <- to save it to a new object!\nStep 2: Write the filtered data frame to a file called “ipeds_completers_ca.csv” in your modified folder."
  },
  {
    "objectID": "04_lesson.html#other-delimiters",
    "href": "04_lesson.html#other-delimiters",
    "title": "4  Data Import",
    "section": "10.2 Other Delimiters",
    "text": "10.2 Other Delimiters\nMost plain text files will use a comma to separate values. Sometimes you’ll see other delimiters used - the most common are tabs \\t and vertical bar | (which is often called a pipe, not to be confused with the tidyverse pipe %>%).\nTo read in a plain text file that uses another delimiter, use the read_delim function. This function will take two arguments: the path to the file you want to load and the character to use as a delimiter.\n\n10.2.1 Example\nFirst we’ll download a tab delimited file from the North Carolina Board of Elections:\n\ndownload_data(\"https://s3.amazonaws.com/dl.ncsbe.gov/data/ncvhis30.zip\",\n              \"data/ncvhis30.zip\")\n\nThen load in the file with the correct delimiter set. It may be helpful to open delimtied file with a program like Notepad so you can see the plain text in the file and decide what delimiter to use. In this case we know its a tab:\n\nncvhis <- read_delim(\"data/ncvhis30.zip\", delim = \"\\t\")\n\nNote that readr was able to read the data directly from the zipfile!\nSimilarly, the write_delim() function can be used to write out a plain text file with a specified delim argument.\n\n\n10.2.2 Exercise\nStep 1: Use write_delim() to write out ncvhis to a pipe | separated file."
  },
  {
    "objectID": "04_lesson.html#common-issues",
    "href": "04_lesson.html#common-issues",
    "title": "4  Data Import",
    "section": "10.3 Common Issues",
    "text": "10.3 Common Issues\nNot all data import will be quick and easy. Often times you will run into issues - these can be daunting at first but are often not as bad as they seem.\n\n10.3.1 Example\nThe readr package provides a challenge.csv file that will throw numerous parsing issues.\n\nchallenge <- read_csv(readr_example(\"challenge.csv\"))\n\nYou can use the problems function to get a tibble of these issues.\n\nissues <- problems(challenge)\n\nA thousand parsing failures sounds like a lot! But it’s really just one error a thousand times, and not a thousand unique errors to work through.\nThe issue is that readr will read the first thousand lines of a file and use that as the column specification. This file changes data types at line 1001. This is a very common issue when reading text files into R. We can use the guess_max argument to increase the number of lines readr will use to set the column types.\n\nchallenge <- read_csv(readr_example(\"challenge.csv\"),\n                      guess_max = Inf)\n\nYou will run into other problems when importing data like:\n\nthe columns not being in the first row\nweird NA values\nblank rows at the top of files\n\nLuckily read_csv() and its friends have a lot of built in arguments to help deal with those issues. Look at the arguments in the docs using ?read_csv or go to the R4DS data import page for examples of how to deal with all the above problems.\n\n\n10.3.2 Exercise\nStep 1: Pull up the documentation for read_csv and take a look of some of the function arguments. There are a lot! You don’t need to know how everything works, but it’s good to have an idea of some of the options available to you."
  },
  {
    "objectID": "04_lesson.html#example-3",
    "href": "04_lesson.html#example-3",
    "title": "4  Data Import",
    "section": "11.1 Example",
    "text": "11.1 Example\nFor this example we’ll download data from the HUD FHA Single Family Portfolio Snap Shot.\n\ndownload_data(\"https://www.hud.gov/sites/dfiles/Housing/documents/FHA_SFSnapshot_Apr2019.xlsx\",\n              \"data/sfsnap.xlsx\")\n\nThis Excel file contains a number of tables on different sheets of the workbook. We can see a listing of the sheets using the excel_sheets function. As usual, the first argument is the path to the data file.\n\nexcel_sheets(\"data/sfsnap.xlsx\")\n\nWe can then use the read_excel function to load our data into our R session. Again, the first argument is the path to the .xlsx file. We also use the sheet argument to specify which sheet of the workbook we want.\n\npurchases <- read_excel(\"data/sfsnap.xlsx\", sheet = \"Purchase Data April 2019\")\n\nNote that the readxl package only provides functionality to, as the name implies, read Excel files. If you need to write your data out to .xls or .xlsx formats - don’t! We highly recommend saving data files as .csv files wherever possible. But if you you really need to, look into the writexl or openxlsx packages."
  },
  {
    "objectID": "04_lesson.html#exercise-4",
    "href": "04_lesson.html#exercise-4",
    "title": "4  Data Import",
    "section": "11.2 Exercise",
    "text": "11.2 Exercise\nStep 1: Use read_excel() to load in the table on the “Refinance Data April 2019” sheet into a data frame called refinances."
  },
  {
    "objectID": "04_lesson.html#stata-data-.dta",
    "href": "04_lesson.html#stata-data-.dta",
    "title": "4  Data Import",
    "section": "12.1 Stata Data (.dta)",
    "text": "12.1 Stata Data (.dta)\n\n12.1.1 Example\nFirst we’ll download and unzip the 2018 General Social Survey, which comes as a zipped .dta file.\n\ndownload_data(\"http://gss.norc.org/Documents/stata/2018_stata.zip\",\n              \"data/gss.zip\")\n\nunzip(\"data/gss.zip\", exdir = \"data/\")\n\nTo read a .dta file, we’ll use the aptly named read_dta function. As usual, the first argument to the function is the path to the data we want to import.\n\ngss <- read_dta(\"data/GSS2018.dta\")\n\n# We can also read in the zip file directly!\ngss <- read_dta(\"data/gss.zip\")"
  },
  {
    "objectID": "04_lesson.html#sas-data-.sas7bdat",
    "href": "04_lesson.html#sas-data-.sas7bdat",
    "title": "4  Data Import",
    "section": "12.2 SAS Data (.sas7bdat)",
    "text": "12.2 SAS Data (.sas7bdat)\nWe use read_sas to read in SAS files. This works mostly identical to read_stata, and you can read in .sas7bdat + .sas7bcat, or zipped folders with sas files. Note that while the write_sas() function exists, it doesn’t appear to actually work at the current version of haven.\n\n12.2.1 Example\nDownload and read in the 2017 1-year Public Use Microsample for Wyoming from the Census:\n\ndownload_data(\"https://www2.census.gov/programs-surveys/acs/data/pums/2017/1-Year/unix_pwy.zip\",\n              \"data/pums_wy.zip\")\n\n# Unzip the files\nunzip(\"data/pums_wy.zip\", exdir = \"data/\")\n\n# Read in sas file\npums_data = read_sas(\"data/pums_wy.zip\")\n\n# Write out as dta file\npums_data %>% write_dta(\"modified/pums_wy.dta\")"
  },
  {
    "objectID": "05_lesson.html",
    "href": "05_lesson.html",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "",
    "text": "6 Review\nThere is less need to write code for control flow in R. First, everything is vectorized so there is rarely a need to iterate to manipulate a vector.\nOn Day 2 we introduced a number of dplyr functions:\nSometimes we will want to apply these functions many times. For example, what if we want to manipulate many variables. For this, we will use the new across() function. To demonstrate across(), we’ll use the built-in mtcars data frame:\nSometimes we want to use across() with many variables but not all variables or not all variables of a certain type. We can use a character vector to pick a subset of columns.\nSometimes this is cumbersome. Fortunately, library(dplyr) has helpers that can create character vectors for use. For instance, if all of the variables we care about start with “e”, then we can\nThere are several selector helpers:\nWarning: across() is not an excuse to avoid tidy data! For example, the following is bad. Why does this violate tidy data? How much pain would we experience if we wanted to plot this data?\nWe use pivot_longer() to transform data from wide to long and pivot_wider() to transform data from long to wide.\nWe can fix the above data with pivot_longer()\nWe can unfix the data with pivot_wider()\nSometimes, we’re going to want to iterate on a data structure other than a tibble or iterate a function that isn’t vectorized."
  },
  {
    "objectID": "05_lesson.html#mutate",
    "href": "05_lesson.html#mutate",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "9.1 mutate()",
    "text": "9.1 mutate()\nSay we wanted to round all the variables of this data frame. We could write some very repetitive code:\n\nmtcars %>%\n  mutate(\n    mpg = round(mpg),\n    cyl = round(cyl),\n    disp = round(disp),\n    hp = round(hp),\n    drat = round(drat),\n    wt = round(wt),\n    qsec = round(qsec),\n    vs = round(vs),\n    am = round(am),\n    gear = round(gear),\n    carb = round(carb)\n  )\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1    21     6   160   110     4     3    16     0     1     4     4\n 2    21     6   160   110     4     3    17     0     1     4     4\n 3    23     4   108    93     4     2    19     1     1     4     1\n 4    21     6   258   110     3     3    19     1     0     3     1\n 5    19     8   360   175     3     3    17     0     0     3     2\n 6    18     6   225   105     3     3    20     1     0     3     1\n 7    14     8   360   245     3     4    16     0     0     3     4\n 8    24     4   147    62     4     3    20     1     0     4     2\n 9    23     4   141    95     4     3    23     1     0     4     2\n10    19     6   168   123     4     3    18     1     0     4     4\n# ℹ 22 more rows\n\n\nOr we can let across() do the work for us. All we have to do is pass the function we want applied to all columns of our data frame:\n\nmtcars %>%\n  mutate(across(.cols = everything(), .fns = round))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1    21     6   160   110     4     3    16     0     1     4     4\n 2    21     6   160   110     4     3    17     0     1     4     4\n 3    23     4   108    93     4     2    19     1     1     4     1\n 4    21     6   258   110     3     3    19     1     0     3     1\n 5    19     8   360   175     3     3    17     0     0     3     2\n 6    18     6   225   105     3     3    20     1     0     3     1\n 7    14     8   360   245     3     4    16     0     0     3     4\n 8    24     4   147    62     4     3    20     1     0     4     2\n 9    23     4   141    95     4     3    23     1     0     4     2\n10    19     6   168   123     4     3    18     1     0     4     4\n# ℹ 22 more rows\n\n\nTo supply your own expression, we can write our own function and pass it through to across():\n\ndivide_by_ten <- function(x) {\n  new_x <- x / 10\n\n  return(new_x)\n}\n\nmtcars %>%\n  mutate(across(.cols = everything(), .fns = divide_by_ten))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  2.1    0.6  16    11   0.39  0.262  1.65   0     0.1   0.4   0.4\n 2  2.1    0.6  16    11   0.39  0.288  1.70   0     0.1   0.4   0.4\n 3  2.28   0.4  10.8   9.3 0.385 0.232  1.86   0.1   0.1   0.4   0.1\n 4  2.14   0.6  25.8  11   0.308 0.322  1.94   0.1   0     0.3   0.1\n 5  1.87   0.8  36    17.5 0.315 0.344  1.70   0     0     0.3   0.2\n 6  1.81   0.6  22.5  10.5 0.276 0.346  2.02   0.1   0     0.3   0.1\n 7  1.43   0.8  36    24.5 0.321 0.357  1.58   0     0     0.3   0.4\n 8  2.44   0.4  14.7   6.2 0.369 0.319  2      0.1   0     0.4   0.2\n 9  2.28   0.4  14.1   9.5 0.392 0.315  2.29   0.1   0     0.4   0.2\n10  1.92   0.6  16.8  12.3 0.392 0.344  1.83   0.1   0     0.4   0.4\n# ℹ 22 more rows\n\n\nOr we can write it inline using the following syntax where ~ lets dplyr know to expect an inline function, and . is used as a placeholder for the variable.\n\nmtcars %>%\n  mutate(across(.cols = everything(), .fns = ~ . / 10))\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  2.1    0.6  16    11   0.39  0.262  1.65   0     0.1   0.4   0.4\n 2  2.1    0.6  16    11   0.39  0.288  1.70   0     0.1   0.4   0.4\n 3  2.28   0.4  10.8   9.3 0.385 0.232  1.86   0.1   0.1   0.4   0.1\n 4  2.14   0.6  25.8  11   0.308 0.322  1.94   0.1   0     0.3   0.1\n 5  1.87   0.8  36    17.5 0.315 0.344  1.70   0     0     0.3   0.2\n 6  1.81   0.6  22.5  10.5 0.276 0.346  2.02   0.1   0     0.3   0.1\n 7  1.43   0.8  36    24.5 0.321 0.357  1.58   0     0     0.3   0.4\n 8  2.44   0.4  14.7   6.2 0.369 0.319  2      0.1   0     0.4   0.2\n 9  2.28   0.4  14.1   9.5 0.392 0.315  2.29   0.1   0     0.4   0.2\n10  1.92   0.6  16.8  12.3 0.392 0.344  1.83   0.1   0     0.4   0.4\n# ℹ 22 more rows"
  },
  {
    "objectID": "05_lesson.html#summarize",
    "href": "05_lesson.html#summarize",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "9.2 summarize()",
    "text": "9.2 summarize()\nSay we wanted to find the mean of every variable in the mtcars data. In this case we can still use across()!\n\nmtcars %>%\n  summarize(across(.cols = everything(), .fns = mean))\n\n# A tibble: 1 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  20.1  6.19  231.  147.  3.60  3.22  17.8 0.438 0.406  3.69  2.81\n\n\nWe can calculate multiple summary statistics by passing in a list() of the statistics we want:\n\nmtcars %>%\n  summarize(\n    n = n(),\n    across(\n      .cols = everything(),\n      .fns = list(mean = mean, median = median)\n    )\n  )\n\n# A tibble: 1 × 25\n      n mpg_mean mpg_median cyl_mean cyl_median disp_mean disp_median hp_mean\n  <int>    <dbl>      <dbl>    <dbl>      <dbl>     <dbl>       <dbl>   <dbl>\n1    32     20.1       19.2     6.19          6      231.        196.    147.\n# ℹ 17 more variables: hp_median <dbl>, drat_mean <dbl>, drat_median <dbl>,\n#   wt_mean <dbl>, wt_median <dbl>, qsec_mean <dbl>, qsec_median <dbl>,\n#   vs_mean <dbl>, vs_median <dbl>, am_mean <dbl>, am_median <dbl>,\n#   gear_mean <dbl>, gear_median <dbl>, carb_mean <dbl>, carb_median <dbl>,\n#   n_mean <dbl>, n_median <int>"
  },
  {
    "objectID": "05_lesson.html#exercise-1",
    "href": "05_lesson.html#exercise-1",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "9.3 Exercise 1",
    "text": "9.3 Exercise 1\nStep 1: Open up a script, save it with a meaningful name, and load the tidyverse.\nStep 2: Use the mutate() and across() to take the log of each variable in mtcars.\nStep 3: Use the summarise() and across() to find the standard deviation (sd) of each variable in mtcars."
  },
  {
    "objectID": "05_lesson.html#example",
    "href": "05_lesson.html#example",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "10.1 Example",
    "text": "10.1 Example\nTo demonstrate where() we’ll use the diamonds data frame from ggplot2:\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\nWhat happens if we try to use mutate(acoss(.cols = everything(), .fns = log)) to log transform each variable in this data frame?\n\ndiamonds %>%\n  mutate(across(.cols = everything(), .fns = log))\n\nError in `mutate()`:\nℹ In argument: `across(.cols = everything(), .fns = log)`.\nCaused by error in `across()`:\n! Can't compute column `cut`.\nCaused by error in `Math.factor()`:\n! 'log' not meaningful for factors\n\n\nIt doesn’t work because diamonds has some non-numeric columns. We could find all the columns that are numeric:\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   <dbl> 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     <ord> Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   <ord> E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity <ord> SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   <dbl> 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   <dbl> 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   <int> 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       <dbl> 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       <dbl> 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       <dbl> 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\nAnd then write a lot of repetitive mutate() statements again. Instead let’s use where() as follows:\n\ndiamonds %>%\n  mutate(across(.cols = where(is.numeric), .fns = log))\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 -1.47 Ideal     E     SI2      4.12  4.01  5.79  1.37  1.38 0.888\n 2 -1.56 Premium   E     SI1      4.09  4.11  5.79  1.36  1.35 0.837\n 3 -1.47 Good      E     VS1      4.04  4.17  5.79  1.40  1.40 0.837\n 4 -1.24 Premium   I     VS2      4.13  4.06  5.81  1.44  1.44 0.967\n 5 -1.17 Good      J     SI2      4.15  4.06  5.81  1.47  1.47 1.01 \n 6 -1.43 Very Good J     VVS2     4.14  4.04  5.82  1.37  1.38 0.908\n 7 -1.43 Very Good I     VVS1     4.13  4.04  5.82  1.37  1.38 0.904\n 8 -1.35 Very Good H     SI1      4.13  4.01  5.82  1.40  1.41 0.928\n 9 -1.51 Fair      E     VS2      4.18  4.11  5.82  1.35  1.33 0.912\n10 -1.47 Very Good H     VS1      4.08  4.11  5.82  1.39  1.40 0.871\n# ℹ 53,930 more rows\n\n\nWhen using the where() with across(), we first supply the condition that must be met, and then the function to apply to the columns that meet that condition. So in the above example, we first test if a column is.numeric, and then apply log to those that are.\nWe can use select() and where() to subset only those columns that are numeric:\n\ndiamonds %>%\n  select(where(is.numeric))\n\n# A tibble: 53,940 × 7\n   carat depth table price     x     y     z\n   <dbl> <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23  61.5    55   326  3.95  3.98  2.43\n 2  0.21  59.8    61   326  3.89  3.84  2.31\n 3  0.23  56.9    65   327  4.05  4.07  2.31\n 4  0.29  62.4    58   334  4.2   4.23  2.63\n 5  0.31  63.3    58   335  4.34  4.35  2.75\n 6  0.24  62.8    57   336  3.94  3.96  2.48\n 7  0.24  62.3    57   336  3.95  3.98  2.47\n 8  0.26  61.9    55   337  4.07  4.11  2.53\n 9  0.22  65.1    61   337  3.87  3.78  2.49\n10  0.23  59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows"
  },
  {
    "objectID": "05_lesson.html#exercise-2",
    "href": "05_lesson.html#exercise-2",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "10.2 Exercise 2",
    "text": "10.2 Exercise 2\nNote: Each step is a separate task. They need not be piped together.\nStep 1: Use select() and where() to subset all the columns from diamonds that are factor variables.\nStep 2: Use the mutate(), across(), and where() to take the sqrt of each numeric variable in diamonds.\nStep 3: Use the summarise, across(), and where() to find the mean and standard deviation of each numeric variable in diamonds.\nStep 4: Use summarise() and across() to find the mean and standard deviation of each numeric variable in diamonds, first using group_by(), across(), and where() to group by all factor variables."
  },
  {
    "objectID": "05_lesson.html#tidy-data",
    "href": "05_lesson.html#tidy-data",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "12.1 Tidy data",
    "text": "12.1 Tidy data\n\nHappy families are all alike; every unhappy family is unhappy in its own way. ~ Leo Tolstoy\n\n\ntidy datasets are all alike but every messy dataset is messy in its own way ~ Hadley Wickham\n\nTools optimized for one data format are going to be more powerful than tools optimized for any data format. If we can standardize our data, then we will have really powerful tools.\nUnfortunately, most people do not pay enough attention to the structure, storage, and dissemination of data."
  },
  {
    "objectID": "05_lesson.html#many-files",
    "href": "05_lesson.html#many-files",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "13.1 Many files",
    "text": "13.1 Many files\nOne approach is to use for loops. For loops are useful and should be understood. This code writes nine .csv files with 1000 random draws from a standard normal distribution.\n\ndir.create(\"data\")\n\nfor (i in 1:9) {\n  tibble(\n    id = 1:1000,\n    value = rnorm(1000)\n  ) %>%\n    write_csv(path = paste0(\"data/data\", i, \".csv\"))\n}\n\nlibrary(purrr) is a powerful alternative to for loops that is designed for functional programming. This code reads in the nine .csv files!\n\nfiles <- list.files(path = \"data\", full.names = TRUE)\n\nmap(.x = files, .f = read_csv)\n\nmap() always returns a list! map_*() functions can be used to return different data structures. For instance, map_chr() will always return a character vector. map_df() is like the code above but returns one data frame instead of a list of smaller data frames.\n\nmap_df(.x = files, .f = read_csv)"
  },
  {
    "objectID": "05_lesson.html#many-models",
    "href": "05_lesson.html#many-models",
    "title": "5  Iteration (or becoming an R Superhero)",
    "section": "13.2 Many models",
    "text": "13.2 Many models\n\nlibrary(broom)\n\n# estimate a linear model for each of seven colors\nmany_models <- diamonds %>%\n  split(diamonds$color) %>%\n  map(~ lm(formula = price ~ carat + cut, data = .))\n\n# extract model diagnostics from each model\nmany_models_results <- bind_cols(\n  color = names(many_models),\n  map_df(many_models, glance)\n)\n\n# plot\nmany_models_results %>%\n  ggplot(aes(color, r.squared)) +\n  geom_col() +\n  scale_y_continuous(\n    expand = c(0, 0),\n    limits = c(0, 1)\n  ) +\n  labs(title = \"R-Squared for linear models estimated on subsets by color\") +\n  theme_minimal()\n\n\n\n\nThese examples are beyond the scope of an introductory class but I wanted to demonstrate the power of iteration in R. These tools can be used iterate data visualizations, R Markdown reports, statistical models, computer operations like file creation and transfer, and more."
  }
]