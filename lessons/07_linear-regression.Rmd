---
title: "Regression in R"
author: "Aaron R. Williams (IBP)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    number_sections: TRUE
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: ../www/web_report.css
    editor_options:
      chunk_output_type: console
---

<style>
@import url('https://fonts.googleapis.com/css?family=Lato&display=swap');
</style>

<link href="https://fonts.googleapis.com/css?family=Lato&display=swap" rel="stylesheet">

```{r echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(modelr)
library(broom)
library(urbnthemes)

set_urbn_defaults(style = "print")

options(scipen = 999)
```

This guide is a brief introduction to code for implementing and evaluating linear regression models in R. It does not address the theory behind linear regression models. To learn more about statistical modeling check out this page of [resources](https://urbaninstitute.github.io/r-at-urban/resources.html). 

# `lm()`

Linear regression models like OLS regression are estimated in R with `lm()`. Here is a simple OLS model with stopping distance as the dependent variable and speed as the independent variable. 

```{r}
lm(formula = dist ~ speed, data = cars)
```

# Wilkinson-Rogers Notation

Oftentimes, we want to specify models with more than one predictor variable. We will use 1,000 observations from the `diamonds` data set to demonstrate additional specifications. 

```{r}
set.seed(20200622)

diamonds <- diamonds %>%
  sample_n(1000) %>%
  mutate(across(where(is.factor), 
         as.character))
```

Regression specification in R is handled by a function notation based on [Symbolic Description of Factorial Models for Analysis of Variance](https://www.jstor.org/stable/2346786?seq=1) by G.N. Wilkinson and C.E. Rogers. It's concise and flexible. The following examples will demonstrate the notation through the model matrix:

## More variables

`+` can be used to add additional predictor variables:

```{r}
model_matrix(formula = price ~ carat + x, data = diamonds)
```

## Categorical variables

`factor()` can be used to add character variables as $n - 1$ dummy variables:

```{r}
model_matrix(formula = price ~ carat + factor(color), data = diamonds)
```

## Transformations

`log()` and `sqrt()` can be used to transform variables directly. Transformations that use `+`, `-`, `*`, `/`, `^`, logical operators need to be wrapped in `I()`.

```{r}
model_matrix(formula = log(price) ~ sqrt(x) + I(y / 1000) + I(z > 1), data = diamonds)
```

## Interactions

`*` (without `I()`) can be used to add interactions. Main effects will automatically be added. Interactions can occur between any combination of continuous and categorical variables. `:` indicates an interation. 

```{r}
model_matrix(formula = price ~ carat * cut, data = diamonds)
```

An `n`th degree polynomial and all lower-order polynomials can be added with `poly()`. Note, the default behavior is to add orthonormal predictors. Add `raw = TRUE` to skips the orthnormal transformation.

```{r}
model_matrix(formula = price ~ poly(carat, degree = 3, raw = TRUE), data = diamonds)
```

Natural splines can be added with `splines::ns()`

```{r}
model_matrix(formula = price ~ splines::ns(carat, df = 9), data = diamonds)
```

## Dropping the intercept

The intercept term can be dropped with `- 1`. 

```{r}
model_matrix(formula = price ~ carat + color - 1, data = diamonds)
```

<br>
<br>
<br>

**Note:** `lm()` is smart and will exclude variables that are linear combinations of other variables 

```{r}
diamonds <- diamonds %>%
  mutate(new_var = 2 * x + y)

lm(formula = price ~ x + y + new_var, data = diamonds)
```

# The lm object

The `lm()` function creates an object of class `"lm"`. Many R functions have convenient methods for this object that are useful for understanding and using the output of a regression model. 

```{r}
diamonds_model1 <- lm(formula = price ~ carat + cut, data = diamonds)

class(diamonds_model1)
```

## Summary

`summary()` returns a regression table with the call, a five number summary of the residuals, coefficient estimates, standard errors, t statistics, p-values, the residual standard error, $R^2$, adjusted $R ^ 2$, the F-statistic, and the p-value for the F-statistic. 

```{r}
summary(diamonds_model1)
```

## Coefficients

`coef()` can be used to select just the coefficients:

```{r}
coef(diamonds_model1)
```

## Residuals

`resid()` can used to select just a vector of the residuals. 

```{r}
resid(diamonds_model1)[1:10]
```

## Diagnostic plots

`plot()` will return four plots with regression diagnostics. 

* **(1) Residual plot:** This demonstrates if the residuals have non-linear patterns or non-constant variance. 
* **(2) Normal QQ plot:** This demonstrates if the residuals are normally distributed. 
* **(3) Scale-Location plot:** This also demonstrates if the residuals have non-constant variance.
* **(4): Residuals vs. leverage plot** This demonstrates cases that may be influential.

```{r}
plot(diamonds_model1)
```

## ANOVA comparison

ANOVA tables can be used to compare nested regression specifications. The test evaluates if the more-complicated model is significantly better at capturing the variation in the data than the simpler model. 

```{r}

diamonds_model2 <- lm(price ~ carat + cut + color, data = diamonds)

anova(diamonds_model1, 
      diamonds_model2)
```

# `library(modelr)`

`library(modelr)` has many useful functions for modeling. It works with more types of models than just linear models from `lm()`. 

## `add_predictions()`

`add_predictions()` adds predictions to a data set using an estimated model object. 

```{r}
add_predictions(data = diamonds, model = diamonds_model1)
```

## `add_residuals()`

`add_residuals()` adds residuals to a data set using an estimated model object. 

```{r}
add_residuals(data = diamonds, model = diamonds_model1)
```

## `data_grid()`

`data_grid()` creates an evenly-spaced grid of points using the range of observed predictors in a data set. This is useful for visualization and is really, really useful for understanding generalized linear models. 

```{r}
data_grid(data = diamonds, carat, cut) %>%
  add_predictions(diamonds_model1)
```

```{r echo = FALSE}
cut_levels <- c("Fair", "Good",  "Very Good", "Ideal", "Premium")

data_grid(data = diamonds, carat, cut) %>%
  add_predictions(diamonds_model1) %>%
  mutate(cut = factor(cut, levels = cut_levels)) %>%
  ggplot(aes(carat, pred, color = cut)) +
  geom_line(alpha = 0.5) +
  scale_x_continuous(limits = c(0, 3),
                     expand = c(0, 0)) +
  scale_y_continuous(limits = c(-5000, 20000),
                     expand = c(0, 0),
                     labels = scales::dollar) +
  scatter_grid() +
  labs(title = "data_grid is useful for interpreting the regression line")
```

# `library(broom)`

`library(broom)` contains three helpful functions for tidying the output of estimated models. It has methods for many types of models. We will demonstrate applications with `lm()`. 

Estimated regression functions have diagnostics at the model level, at the coefficient level, and at the observation level. 

## `glance()`

`glance()` returns model-level diagnostics like $R^2$ and $\hat{\sigma}$. 

```{r}
glance(diamonds_model1)
```

## `tidy()`

`tidy()` returns coefficient-level diagnostics like standard errors and p-values.

```{r}
tidy(diamonds_model1)
```

## `augment()`

`augment()` returns observation-level diagnostics like residuals and hat values. 

```{r}
augment(diamonds_model1)
```

# Data viz

`library(broom)` is incredibly helpful for data visualization. 

## Coefficient plot

Here's a simple plot of estimated OLS coefficients and their 95% confidence intervals. 

```{r}
tidy(diamonds_model1, 
     conf.int = TRUE,
     conf.level = 0.95) %>%
  ggplot(aes(x = estimate, 
             y = term,
             xmin = conf.low,
             xmax = conf.high)) +
  geom_pointrange() +
  geom_vline(xintercept = 0) +
  scale_x_continuous(limits = c(-10000, 10000),
                     labels = scales::dollar) +
  scatter_grid() +
  labs()
```

## Residual plot

Here's an even simpler residual plot. The non-constant errors are a big issue and our specification is clearly inadequate!

```{r}
augment(diamonds_model1) %>%
  ggplot(aes(.fitted, .resid)) +
  geom_point(alpha = 0.2) +
  scatter_grid()
```

## Many models

```{r}
# estimate a linear model for each of seven colors
many_models <- diamonds %>%
  split(diamonds$color) %>%
  map(~lm(formula = price ~ carat + cut, data = .))

# extract model diagnostics from each model
many_models_results <- bind_cols(
  color = names(many_models), 
  map_df(many_models, glance)
)

# plot
many_models_results %>%
  ggplot(aes(color, r.squared)) +
  geom_col() +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, 1)) +
  labs(title = "R-Squared for linear models estimated on subsets by color") +
  remove_ticks()
```

[Hadley Wickham gave a great talk about this to the The Edinburgh R User Group.](https://www.youtube.com/watch?v=rz3_FDVt9eg)

# Extras

This last section covers a few more useful topics. 

## `library(stargazer)`

`library(stargazer)` creates publishable regression tables.

```{r results = "asis"}
stargazer::stargazer(diamonds_model1, type = "html")
```

## `glm()`

`glm()` is the workhorse function for generalized linear models like logistic regression and Poisson regression. 

`gam()` is used for generalized additive models. 

## Econometrics

R was originally written by statisticians. Many regression methods were originally implemented in R and most regression methods have been implemented in R. The key is to find the correct packages. 

[CRAN task views](https://cran.r-project.org/web/views/) are curated collections of packages and and methods for specific disciplines. The econometrics CRAN task view is maintained by the author of Applied Econometrics with R. 

[Introduction to Econometrics with R](https://www.econometrics-with-r.org/) is a new text that walks through many econometric methods and contains examples in R. It contains more narrative and application than CRAN Task Views.  

[Using R for Introductory Econometrics](http://www.urfie.net/) is a companion book for Wooldridge's "Introductory Econometrics: A Modern Approach". I have a print copy that I can share. It contains examples of implementing methods from scratch but is a little light on modern packages for advanced methods. 
